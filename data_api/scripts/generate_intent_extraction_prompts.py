#!/usr/bin/env python3
"""
ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ

å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ„å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡ºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ

ä½¿ç”¨ä¾‹:
  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ç”Ÿæˆ
  python scripts/generate_intent_extraction_prompts.py

  # Gemini APIã§æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨HTMLã‚’ç”Ÿæˆ
  python scripts/generate_intent_extraction_prompts.py --gemini
"""

import json
import pandas as pd
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime
import argparse
import os
from dotenv import load_dotenv
import google.generativeai as genai
from diskcache import Cache
from tqdm import tqdm
import hashlib


OUTPUT_DIR = Path("output/intent_extraction")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

CACHE_DIR = Path("output/.cache/intent_extraction")
CACHE_DIR.mkdir(parents=True, exist_ok=True)
cache = Cache(str(CACHE_DIR))

TEMPLATE_DIR = Path("templates")
TEMPLATE_FILE = TEMPLATE_DIR / "intent_extraction_prompt.md"

PROCESSED_DIR = OUTPUT_DIR / "processed"
PROCESSED_DIR.mkdir(parents=True, exist_ok=True)


def load_template() -> str:
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
    if not TEMPLATE_FILE.exists():
        raise FileNotFoundError(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {TEMPLATE_FILE}")

    with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
        return f.read()


def load_clustered_messages() -> pd.DataFrame:
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿"""
    csv_path = Path("output/message_clustering/clustered_messages.csv")
    if not csv_path.exists():
        raise FileNotFoundError(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")

    df = pd.read_csv(csv_path)
    df['start_time'] = pd.to_datetime(df['start_time'])
    return df


def build_message_metadata(df: pd.DataFrame) -> Dict[str, Dict]:
    """
    ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸IDã‹ã‚‰ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’æ§‹ç¯‰

    Args:
        df: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®DataFrame

    Returns:
        msg_id -> {full_path, min_start_timestamp} ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    """
    metadata = {}
    for row in df.itertuples():
        msg_id = row.message_id
        if msg_id not in metadata:
            metadata[msg_id] = {
                'full_path': row.full_path,
                'min_start_timestamp': row.start_time.isoformat()
            }
        else:
            # åŒã˜msg_idã§è¤‡æ•°è¡Œã‚ã‚‹å ´åˆã€æœ€å°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿æŒ
            current_ts = pd.to_datetime(metadata[msg_id]['min_start_timestamp'])
            if row.start_time < current_ts:
                metadata[msg_id]['min_start_timestamp'] = row.start_time.isoformat()
    return metadata


def generate_cluster_prompt(cluster_id: int, cluster_df: pd.DataFrame, template: str) -> Dict:
    """
    1ã¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å¯¾ã™ã‚‹æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ

    Args:
        cluster_id: ã‚¯ãƒ©ã‚¹ã‚¿ID
        cluster_df: ã‚¯ãƒ©ã‚¹ã‚¿ã«å±ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®DataFrame
        template: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

    Returns:
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæƒ…å ±ã®è¾æ›¸
    """
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
    cluster_df = cluster_df.sort_values('start_time')

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’æ§‹ç¯‰
    messages = []
    message_parts = []

    for i, row in enumerate(cluster_df.itertuples(), 1):
        msg = {
            'message_id': row.message_id,
            'channel': row.full_path,
            'time': row.start_time.strftime('%Y-%m-%d %H:%M'),
            'content': row.combined_content
        }
        messages.append(msg)

        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸éƒ¨åˆ†ã®ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
        message_parts.extend([
            f"### ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i}",
            f"- ID: `{msg['message_id']}`",
            f"- ãƒãƒ£ãƒãƒ«: {msg['channel']}",
            f"- æ—¥æ™‚: {msg['time']}",
            f"- å†…å®¹:",
            "```",
            msg['content'],
            "```",
            ""
        ])

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«å€¤ã‚’åŸ‹ã‚è¾¼ã¿
    prompt_text = template.format(
        cluster_id=cluster_id,
        message_count=len(messages),
        period_start=cluster_df['start_time'].min().strftime('%Y-%m-%d'),
        period_end=cluster_df['start_time'].max().strftime('%Y-%m-%d'),
        messages="\n".join(message_parts)
    )

    return {
        'cluster_id': cluster_id,
        'message_count': len(messages),
        'prompt': prompt_text,
        'messages': messages
    }


def preprocess_extract_json_from_response(text: str) -> Optional[List[Dict]]:
    """
    ã€å‰å‡¦ç†ã€‘ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰JSONã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹

    Args:
        text: Gemini APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸJSONï¼ˆãƒªã‚¹ãƒˆï¼‰ã¾ãŸã¯None
    """
    text = text.strip()

    # ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
    if "```json" in text:
        start = text.find("```json") + 7
        end = text.find("```", start)
        json_text = text[start:end].strip()
    elif "```" in text:
        start = text.find("```") + 3
        end = text.find("```", start)
        json_text = text[start:end].strip()
    else:
        json_text = text

    # JSONãƒ‘ãƒ¼ã‚¹
    try:
        result = json.loads(json_text)
        if not isinstance(result, list):
            return None
        return result
    except json.JSONDecodeError:
        return None


def postprocess_enrich_and_save_intents(
    raw_response_text: str,
    cluster_id: int,
    message_metadata: Dict[str, Dict]
) -> Optional[List[Dict]]:
    """
    ã€å¾Œå‡¦ç†ã€‘ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡ºã—ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œã—ã¦ä¿å­˜

    Args:
        raw_response_text: Gemini APIã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹
        cluster_id: ã‚¯ãƒ©ã‚¹ã‚¿ID
        message_metadata: msg_id -> {full_path, min_start_timestamp} ã®ãƒãƒƒãƒ”ãƒ³ã‚°

    Returns:
        å‡¦ç†å¾Œã®æ„å›³ãƒªã‚¹ãƒˆã€ã¾ãŸã¯None
    """
    # JSONã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆå‰å‡¦ç†ï¼‰
    intents = preprocess_extract_json_from_response(raw_response_text)
    if intents is None:
        return None

    # å„æ„å›³ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    for intent in intents:
        # cluster_idã‚’è¿½åŠ ï¼ˆint64 -> int å¤‰æ›ï¼‰
        intent['cluster_id'] = int(cluster_id)

        source_ids = intent.get('source_message_ids', [])
        if not source_ids:
            continue

        # source_message_idsã«å¯¾å¿œã™ã‚‹full_pathã¨min_start_timestampã‚’é›†ç´„
        full_paths = []
        timestamps = []

        for msg_id in source_ids:
            metadata = message_metadata.get(msg_id, {})
            full_path = metadata.get('full_path')
            timestamp = metadata.get('min_start_timestamp')

            if full_path:
                full_paths.append(full_path)
            if timestamp:
                timestamps.append(timestamp)

        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªfull_pathã®ãƒªã‚¹ãƒˆ
        intent['source_full_paths'] = list(set(full_paths)) if full_paths else []

        # æœ€å°ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        intent['min_start_timestamp'] = min(timestamps) if timestamps else None

    # å‡¦ç†å¾Œã®JSONã‚’ä¿å­˜
    output_file = PROCESSED_DIR / f"cluster_{cluster_id:02d}_processed.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(intents, f, ensure_ascii=False, indent=2)

    return intents


def call_gemini_api_with_postprocess(
    prompt_text: str,
    cluster_id: int,
    message_metadata: Dict[str, Dict],
    save_raw: bool = False
) -> Optional[List[Dict]]:
    """
    ã€APIå‘¼ã³å‡ºã— + å¾Œå‡¦ç†ã€‘Gemini APIã‚’ä½¿ã£ã¦æ„å›³ã‚’æŠ½å‡ºï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰

    Args:
        prompt_text: æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        cluster_id: ã‚¯ãƒ©ã‚¹ã‚¿ID
        message_metadata: msg_id -> {full_path, min_start_timestamp} ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        save_raw: ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹ã‹

    Returns:
        æŠ½å‡ºã•ã‚ŒãŸæ„å›³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ã¯Noneï¼‰
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã§åˆ¤å®šï¼‰
    cache_key = f"intent_extraction_{hashlib.md5(prompt_text.encode()).hexdigest()}"

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    cached_data = cache.get(cache_key)

    if cached_data is not None and isinstance(cached_data, str):
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼ˆæ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰: ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¯¾ã—ã¦å¾Œå‡¦ç†ã‚’å®Ÿè¡Œ
        response_text = cached_data
    else:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: APIå‘¼ã³å‡ºã—
        try:
            model = genai.GenerativeModel("gemini-2.5-flash")
            response = model.generate_content(prompt_text)
            response_text = response.text

            # ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            cache.set(cache_key, response_text)

        except Exception as e:
            print(f"\nâŒ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {type(e).__name__}: {e}")
            raise

    # ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if save_raw:
        raw_output_dir = OUTPUT_DIR / "raw_responses"
        raw_output_dir.mkdir(exist_ok=True)
        raw_file = raw_output_dir / f"cluster_{cluster_id:02d}_raw_response.txt"
        with open(raw_file, 'w', encoding='utf-8') as f:
            f.write(response_text)

    # å¾Œå‡¦ç†ã‚’å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã‚‚æ¯å›å®Ÿè¡Œï¼‰
    intents = postprocess_enrich_and_save_intents(
        response_text,
        cluster_id,
        message_metadata
    )

    return intents


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹
    parser = argparse.ArgumentParser(
        description="ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§Gemini APIã«ã‚ˆã‚‹æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œ"
    )
    parser.add_argument(
        "--gemini",
        action="store_true",
        help="Gemini APIã§æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨HTMLã‚’ç”Ÿæˆ"
    )
    parser.add_argument(
        "--cluster",
        type=int,
        help="ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚¿IDã®ã¿å‡¦ç†ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…¨ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰"
    )
    parser.add_argument(
        "--save-raw",
        action="store_true",
        help="Gemini APIã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"
    )
    args = parser.parse_args()

    print("=" * 60)
    print("æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ")
    if args.gemini:
        print("+ Gemini API ã§æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œ")
    if args.cluster is not None:
        print(f"+ ã‚¯ãƒ©ã‚¹ã‚¿ {args.cluster} ã®ã¿å‡¦ç†")
    if args.save_raw:
        print("+ ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜")
    print("=" * 60)

    # Gemini API ã®åˆæœŸåŒ–ï¼ˆ--gemini ã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šæ™‚ï¼‰
    if args.gemini:
        load_dotenv()
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("âŒ ã‚¨ãƒ©ãƒ¼: GEMINI_API_KEY ãŒ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        genai.configure(api_key=api_key)
        print("âœ“ Gemini API ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        print(f"âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {CACHE_DIR}")
        print(f"âœ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º: {len(cache)}ä»¶")

    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿
    print("\nãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
    try:
        template = load_template()
        print(f"âœ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {TEMPLATE_FILE}")
    except FileNotFoundError as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")
    df = load_clustered_messages()
    print(f"âœ“ {len(df)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
    print("\nãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ä¸­...")
    message_metadata = build_message_metadata(df)
    print(f"âœ“ {len(message_metadata)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ")

    # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    cluster_ids = sorted(df['cluster'].unique())

    # ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚¿ã®ã¿å‡¦ç†ã™ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if args.cluster is not None:
        if args.cluster not in cluster_ids:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: ã‚¯ãƒ©ã‚¹ã‚¿ {args.cluster} ã¯å­˜åœ¨ã—ã¾ã›ã‚“")
            print(f"åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã‚¿ID: {cluster_ids}")
            return
        cluster_ids = [args.cluster]

    print(f"\n{len(cluster_ids)}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å¯¾ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã™")

    # æ—¢å­˜ã®çµæœã‚’èª­ã¿è¾¼ã¿ï¼ˆéƒ¨åˆ†æ›´æ–°ã®å ´åˆï¼‰
    all_prompts = []
    if args.cluster is not None and (OUTPUT_DIR / "generation_summary.json").exists():
        # æ—¢å­˜ã®ã‚µãƒãƒªãƒ¼ã‹ã‚‰ä»–ã®ã‚¯ãƒ©ã‚¹ã‚¿ã®æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        with open(OUTPUT_DIR / "generation_summary.json", 'r', encoding='utf-8') as f:
            existing_summary = json.load(f)
        # æ—¢å­˜ã®æŠ½å‡ºçµæœã‚‚èª­ã¿è¾¼ã¿ï¼ˆHTMLå†ç”Ÿæˆã®ãŸã‚ï¼‰
        # ã“ã“ã§ã¯ç°¡ç•¥åŒ–ã®ãŸã‚ã€æŒ‡å®šã‚¯ãƒ©ã‚¹ã‚¿ã®ã¿å†ç”Ÿæˆ

    # tqdmã§é€²æ—è¡¨ç¤º
    progress_desc = "Gemini API ã§æ„å›³æŠ½å‡ºä¸­" if args.gemini else "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆä¸­"
    for cluster_id in tqdm(cluster_ids, desc=progress_desc, unit="cluster"):
        cluster_df = df[df['cluster'] == cluster_id]
        prompt_info = generate_cluster_prompt(cluster_id, cluster_df, template)

        # Gemini APIã§æ„å›³æŠ½å‡ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³æŒ‡å®šæ™‚ï¼‰
        if args.gemini:
            intents = call_gemini_api_with_postprocess(
                prompt_info['prompt'],
                cluster_id,
                message_metadata,
                save_raw=args.save_raw
            )
            prompt_info['extracted_intents'] = intents

            # tqdmã®é€²æ—ãƒãƒ¼å¤–ã«è©³ç´°ã‚’è¡¨ç¤º
            status = f"âœ“ {len(intents)}ä»¶" if intents else "âœ— å¤±æ•—"
            tqdm.write(f"  ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id:2d} ({prompt_info['message_count']:3d}ä»¶): {status}")

        all_prompts.append(prompt_info)

        # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        output_file = OUTPUT_DIR / f"cluster_{cluster_id:02d}_prompt.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(prompt_info['prompt'])
            

    # ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’ä¿å­˜
    summary = {
        'generated_at': datetime.now().isoformat(),
        'total_clusters': int(len(cluster_ids)),
        'total_messages': int(len(df)),
        'clusters': [
            {
                'cluster_id': int(p['cluster_id']),
                'message_count': int(p['message_count']),
                'prompt_file': f"cluster_{p['cluster_id']:02d}_prompt.md"
            }
            for p in all_prompts
        ]
    }

    summary_file = OUTPUT_DIR / "generation_summary.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’ä¿å­˜: {summary_file}")

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®HTMLã‚’ç”Ÿæˆ
    if args.gemini:
        # GeminiæŠ½å‡ºçµæœã®ãƒ¬ãƒ“ãƒ¥ãƒ¼HTML
        generate_intent_review_html(all_prompts)
        print("\n" + "=" * 60)
        print("âœ… æ„å›³æŠ½å‡ºå®Œäº†ï¼")
        print("=" * 60)
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
        print(f"ğŸ“„ ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨HTML: {OUTPUT_DIR / 'intent_review.html'}")
        print(f"ğŸ“„ å¾Œå‡¦ç†æ¸ˆã¿JSON: {PROCESSED_DIR}/")
        print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  1. {OUTPUT_DIR}/intent_review.html ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã")
        print(f"  2. æŠ½å‡ºã•ã‚ŒãŸæ„å›³ã‚’ç¢ºèªãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        print(f"  3. {PROCESSED_DIR}/ ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª")
    else:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹HTML
        generate_review_index(all_prompts)
        print("\n" + "=" * 60)
        print("âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†ï¼")
        print("=" * 60)
        print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
        print(f"ğŸ“„ ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {OUTPUT_DIR / 'index.html'}")
        print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"  1. {OUTPUT_DIR}/index.html ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã")
        print(f"  2. å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        print(f"  3. --gemini ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œ")


def generate_intent_review_html(all_prompts: List[Dict]):
    """GeminiæŠ½å‡ºçµæœã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨HTMLã‚’ç”Ÿæˆ"""
    html_parts = [
        "<!DOCTYPE html>",
        "<html lang='ja'>",
        "<head>",
        "  <meta charset='UTF-8'>",
        "  <meta name='viewport' content='width=device-width, initial-scale=1.0'>",
        "  <title>æ„å›³æŠ½å‡ºçµæœ - ãƒ¬ãƒ“ãƒ¥ãƒ¼</title>",
        "  <style>",
        "    body { font-family: 'Hiragino Sans', sans-serif; margin: 20px; background: #f5f5f5; }",
        "    .container { max-width: 1400px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }",
        "    h1 { color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }",
        "    .summary { background: #e8f5e9; padding: 15px; border-radius: 5px; margin: 20px 0; }",
        "    .cluster-section { margin: 30px 0; padding: 20px; background: #fafafa; border-radius: 8px; }",
        "    .cluster-header { background: #4CAF50; color: white; padding: 15px; border-radius: 5px; margin-bottom: 15px; }",
        "    .cluster-title { font-size: 1.3em; font-weight: bold; }",
        "    .cluster-meta { margin-top: 5px; font-size: 0.9em; opacity: 0.9; }",
        "    .intents-container { margin-top: 15px; }",
        "    .intent-card { background: white; border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #2196F3; }",
        "    .intent-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 10px; }",
        "    .intent-description { font-size: 1.1em; font-weight: bold; color: #333; }",
        "    .intent-status { padding: 4px 12px; border-radius: 12px; font-size: 0.85em; font-weight: bold; }",
        "    .status-idea { background: #E3F2FD; color: #1976D2; }",
        "    .status-todo { background: #FFF3E0; color: #F57C00; }",
        "    .status-doing { background: #F3E5F5; color: #7B1FA2; }",
        "    .status-done { background: #E8F5E9; color: #388E3C; }",
        "    .intent-field { margin: 8px 0; }",
        "    .field-label { font-weight: bold; color: #666; font-size: 0.9em; }",
        "    .field-value { margin-top: 3px; color: #333; }",
        "    .message-ids { display: flex; flex-wrap: wrap; gap: 5px; margin-top: 5px; }",
        "    .message-id-tag { background: #E0E0E0; padding: 3px 8px; border-radius: 3px; font-size: 0.85em; font-family: monospace; }",
        "    .error-message { background: #FFEBEE; color: #C62828; padding: 15px; border-radius: 5px; border-left: 4px solid #C62828; }",
        "    .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }",
        "    .stat-card { background: white; border: 1px solid #ddd; padding: 15px; border-radius: 5px; text-align: center; }",
        "    .stat-value { font-size: 2em; font-weight: bold; color: #4CAF50; }",
        "    .stat-label { color: #666; font-size: 0.9em; margin-top: 5px; }",
        "  </style>",
        "</head>",
        "<body>",
        "  <div class='container'>",
        "    <h1>ğŸ¯ æ„å›³æŠ½å‡ºçµæœ - ãƒ¬ãƒ“ãƒ¥ãƒ¼</h1>",
    ]

    # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
    total_clusters = len(all_prompts)
    total_intents = sum(len(p.get('extracted_intents', [])) for p in all_prompts if p.get('extracted_intents'))
    failed_clusters = sum(1 for p in all_prompts if not p.get('extracted_intents'))
    success_clusters = total_clusters - failed_clusters

    html_parts.extend([
        "    <div class='summary'>",
        f"      <strong>ç”Ÿæˆæ—¥æ™‚:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>",
        f"      <strong>ãƒ¢ãƒ‡ãƒ«:</strong> Gemini 2.5 Flash",
        "    </div>",
        "    <div class='stats'>",
        f"      <div class='stat-card'><div class='stat-value'>{total_clusters}</div><div class='stat-label'>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</div></div>",
        f"      <div class='stat-card'><div class='stat-value'>{total_intents}</div><div class='stat-label'>æŠ½å‡ºã•ã‚ŒãŸæ„å›³</div></div>",
        f"      <div class='stat-card'><div class='stat-value'>{success_clusters}</div><div class='stat-label'>æˆåŠŸ</div></div>",
        f"      <div class='stat-card'><div class='stat-value'>{failed_clusters}</div><div class='stat-label'>å¤±æ•—</div></div>",
        "    </div>",
    ])

    # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®çµæœã‚’è¡¨ç¤º
    for prompt_info in all_prompts:
        cluster_id = prompt_info['cluster_id']
        message_count = prompt_info['message_count']
        intents = prompt_info.get('extracted_intents')

        html_parts.extend([
            "    <div class='cluster-section'>",
            "      <div class='cluster-header'>",
            f"        <div class='cluster-title'>ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}</div>",
            f"        <div class='cluster-meta'>{message_count}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</div>",
            "      </div>",
        ])

        if intents:
            html_parts.append("      <div class='intents-container'>")
            for i, intent in enumerate(intents, 1):
                status = intent.get('status', 'unknown')
                status_class = f"status-{status}"

                # æ„å›³ã®èª¬æ˜æ–‡ã‚’æŸ”è»Ÿã«å–å¾—ï¼ˆdescription, intent, ãã®ä»–ã®é †ã§æ¢ã™ï¼‰
                description = intent.get('description') or intent.get('intent') or 'ï¼ˆèª¬æ˜ãªã—ï¼‰'

                html_parts.extend([
                    "        <div class='intent-card'>",
                    "          <div class='intent-header'>",
                    f"            <div class='intent-description'>{i}. {description}</div>",
                    f"            <div class='intent-status {status_class}'>{status}</div>",
                    "          </div>",
                ])

                # ç‰¹åˆ¥ãªã‚­ãƒ¼ã‚’é™¤å¤–ã—ã¦ã€æ®‹ã‚Šã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‹•çš„ã«è¡¨ç¤º
                special_keys = {'description', 'intent', 'status', 'source_message_ids'}

                # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
                label_map = {
                    'target': 'å¯¾è±¡',
                    'motivation': 'å‹•æ©Ÿ',
                    'why': 'ç†ç”±',
                    'objective_facts': 'å®¢è¦³çš„äº‹å®Ÿ',
                }

                for key, value in intent.items():
                    if key in special_keys:
                        continue
                    if key == 'source_message_ids':
                        continue
                    if value is None or value == '':
                        continue

                    label = label_map.get(key, key)
                    html_parts.extend([
                        "          <div class='intent-field'>",
                        f"            <div class='field-label'>{label}:</div>",
                        f"            <div class='field-value'>{value}</div>",
                        "          </div>",
                    ])

                # source_message_idsï¼ˆå¸¸ã«è¡¨ç¤ºï¼‰
                if intent.get('source_message_ids'):
                    html_parts.extend([
                        "          <div class='intent-field'>",
                        "            <div class='field-label'>ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ID:</div>",
                        "            <div class='message-ids'>",
                    ])
                    for msg_id in intent['source_message_ids']:
                        html_parts.append(f"              <span class='message-id-tag'>{msg_id}</span>")
                    html_parts.extend([
                        "            </div>",
                        "          </div>",
                    ])

                html_parts.append("        </div>")

            html_parts.append("      </div>")
        else:
            html_parts.append("      <div class='error-message'>âš ï¸ æ„å›³æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ</div>")

        html_parts.append("    </div>")

    html_parts.extend([
        "  </div>",
        "</body>",
        "</html>",
    ])

    output_file = OUTPUT_DIR / "intent_review.html"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(html_parts))

    print(f"\nâœ“ æ„å›³æŠ½å‡ºãƒ¬ãƒ“ãƒ¥ãƒ¼HTMLã‚’ç”Ÿæˆ: {output_file}")


def generate_review_index(all_prompts: List[Dict]):
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã®HTMLã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ"""
    html_parts = [
        "<!DOCTYPE html>",
        "<html lang='ja'>",
        "<head>",
        "  <meta charset='UTF-8'>",
        "  <meta name='viewport' content='width=device-width, initial-scale=1.0'>",
        "  <title>æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ - ãƒ¬ãƒ“ãƒ¥ãƒ¼</title>",
        "  <style>",
        "    body { font-family: 'Hiragino Sans', sans-serif; margin: 20px; background: #f5f5f5; }",
        "    .container { max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }",
        "    h1 { color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; }",
        "    .summary { background: #e8f5e9; padding: 15px; border-radius: 5px; margin: 20px 0; }",
        "    .cluster-list { margin-top: 30px; }",
        "    .cluster-item { background: #fff; border: 1px solid #ddd; padding: 15px; margin: 10px 0; border-radius: 5px; }",
        "    .cluster-item:hover { background: #f9f9f9; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }",
        "    .cluster-header { display: flex; justify-content: space-between; align-items: center; }",
        "    .cluster-id { font-size: 1.2em; font-weight: bold; color: #4CAF50; }",
        "    .message-count { color: #666; font-size: 0.9em; }",
        "    .preview { margin-top: 10px; padding: 10px; background: #f5f5f5; border-left: 3px solid #4CAF50; font-size: 0.85em; max-height: 100px; overflow: hidden; }",
        "    .actions { margin-top: 10px; }",
        "    .btn { display: inline-block; padding: 8px 16px; background: #4CAF50; color: white; text-decoration: none; border-radius: 4px; margin-right: 10px; }",
        "    .btn:hover { background: #45a049; }",
        "    .btn-secondary { background: #2196F3; }",
        "    .btn-secondary:hover { background: #0b7dda; }",
        "  </style>",
        "</head>",
        "<body>",
        "  <div class='container'>",
        "    <h1>ğŸ¯ æ„å›³æŠ½å‡ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ - ãƒ¬ãƒ“ãƒ¥ãƒ¼</h1>",
        "    <div class='summary'>",
        f"      <strong>ç”Ÿæˆæ—¥æ™‚:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}<br>",
        f"      <strong>ã‚¯ãƒ©ã‚¹ã‚¿æ•°:</strong> {len(all_prompts)}<br>",
        f"      <strong>ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°:</strong> {sum(p['message_count'] for p in all_prompts)}",
        "    </div>",
        "    <div class='cluster-list'>",
    ]

    for prompt_info in all_prompts:
        cluster_id = prompt_info['cluster_id']
        message_count = prompt_info['message_count']
        filename = f"cluster_{cluster_id:02d}_prompt.md"

        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã«æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
        first_msg = prompt_info['messages'][0] if prompt_info['messages'] else None
        preview = first_msg['content'][:200] + "..." if first_msg else ""

        html_parts.extend([
            "      <div class='cluster-item'>",
            "        <div class='cluster-header'>",
            f"          <div class='cluster-id'>ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id}</div>",
            f"          <div class='message-count'>{message_count}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸</div>",
            "        </div>",
            f"        <div class='preview'>{preview}</div>",
            "        <div class='actions'>",
            f"          <a href='{filename}' class='btn' target='_blank'>ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é–‹ã</a>",
            f"          <button class='btn btn-secondary' onclick='copyToClipboard(\"{filename}\")'>ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼</button>",
            "        </div>",
            "      </div>",
        ])

    html_parts.extend([
        "    </div>",
        "  </div>",
        "  <script>",
        "    async function copyToClipboard(filename) {",
        "      try {",
        "        const response = await fetch(filename);",
        "        const text = await response.text();",
        "        await navigator.clipboard.writeText(text);",
        "        alert('ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼');",
        "      } catch (err) {",
        "        alert('ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ: ' + err);",
        "      }",
        "    }",
        "  </script>",
        "</body>",
        "</html>",
    ])

    index_file = OUTPUT_DIR / "index.html"
    with open(index_file, 'w', encoding='utf-8') as f:
        f.write("\n".join(html_parts))

    print(f"\nâœ“ ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ: {index_file}")


if __name__ == "__main__":
    main()
