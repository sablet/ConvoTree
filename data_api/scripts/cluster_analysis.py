#!/usr/bin/env python3
"""
ã‚°ãƒ©ãƒ•æ§‹é€ è©•ä¾¡ã¨ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

è¤‡æ•°é–¾å€¤ã§ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ã€ä»¥ä¸‹ã®åŸºæº–ã§æœ€é©ã‚°ãƒ©ãƒ•ã‚’é¸å®šï¼š
1. ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªæ§‹é€ ã®æ˜ç­æ€§
2. ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ã®æ˜ç­æ€§ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£ï¼‰
3. ã‚¨ãƒƒã‚¸é‡ã¿ã®æƒ…å ±é‡ï¼ˆåˆ†æ•£ï¼‰

æœ€é©ã‚°ãƒ©ãƒ•ã«å¯¾ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿æŠ½å‡ºã‚’è¡Œã„ã€è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã€‚
"""

import json
import numpy as np
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
from networkx.algorithms import community
from typing import Dict, List, Tuple, Set
import pandas as pd
from collections import defaultdict

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'Hiragino Sans'
plt.rcParams['axes.unicode_minus'] = False

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = Path("output/cluster_analysis")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def load_embeddings(file_path: str) -> Tuple[List[Dict], np.ndarray, List[str], List[str]]:
    """åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    embeddings = np.array([item['embedding'] for item in data])
    ids = [item['id'] for item in data]
    summaries = [item['summary'] for item in data]

    return data, embeddings, ids, summaries

def compute_similarity_matrix(embeddings: np.ndarray) -> np.ndarray:
    """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—"""
    sim_matrix = cosine_similarity(embeddings)
    np.fill_diagonal(sim_matrix, 0)  # è‡ªå·±é¡ä¼¼åº¦ã‚’é™¤å¤–
    return sim_matrix

def extract_relations(sim_matrix: np.ndarray, ids: List[str], threshold: float) -> List[Tuple[str, str, float]]:
    """é–¾å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’æŒã¤ãƒšã‚¢ã‚’ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦æŠ½å‡º"""
    relations = []
    n = len(ids)
    for i in range(n):
        for j in range(i + 1, n):
            if sim_matrix[i, j] >= threshold:
                relations.append((ids[i], ids[j], sim_matrix[i, j]))
    return relations

def build_graph(relations: List[Tuple[str, str, float]]) -> nx.Graph:
    """ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
    G = nx.Graph()
    for src, dst, weight in relations:
        G.add_edge(src, dst, weight=weight)
    return G

def evaluate_core_periphery(G: nx.Graph) -> Dict:
    """ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªæ§‹é€ ã®è©•ä¾¡"""
    if G.number_of_nodes() == 0:
        return {'score': 0, 'core_size': 0, 'periphery_size': 0}

    degrees = dict(G.degree())
    degree_values = list(degrees.values())

    if not degree_values:
        return {'score': 0, 'core_size': 0, 'periphery_size': 0}

    # æ¬¡æ•°ã®åˆ†æ•£ï¼ˆå¤§ãã„ã»ã©ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªæ§‹é€ ãŒæ˜ç¢ºï¼‰
    degree_variance = np.var(degree_values)
    degree_mean = np.mean(degree_values)

    # ã‚³ã‚¢åˆ¤å®š: å¹³å‡+1æ¨™æº–åå·®ä»¥ä¸Š
    threshold = degree_mean + np.std(degree_values)
    core_nodes = [node for node, deg in degrees.items() if deg >= threshold]
    periphery_nodes = [node for node, deg in degrees.items() if deg < threshold]

    # ã‚³ã‚¢ã®å¯†åº¦ã¨ãƒšãƒªãƒ•ã‚§ãƒªã®å¯†åº¦ã®æ¯”
    core_subgraph = G.subgraph(core_nodes)
    core_density = nx.density(core_subgraph) if len(core_nodes) > 1 else 0

    periphery_subgraph = G.subgraph(periphery_nodes)
    periphery_density = nx.density(periphery_subgraph) if len(periphery_nodes) > 1 else 0

    # ã‚¹ã‚³ã‚¢: å¯†åº¦æ¯”ã¨æ¬¡æ•°åˆ†æ•£ã®ç©
    density_ratio = core_density / (periphery_density + 1e-6)
    score = degree_variance * density_ratio

    return {
        'score': float(score),
        'degree_variance': float(degree_variance),
        'density_ratio': float(density_ratio),
        'core_size': len(core_nodes),
        'periphery_size': len(periphery_nodes),
        'core_density': float(core_density),
        'periphery_density': float(periphery_density),
        'core_nodes': core_nodes[:10]  # ã‚µãƒ³ãƒ—ãƒ«
    }

def evaluate_community_structure(G: nx.Graph) -> Dict:
    """ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ã®è©•ä¾¡ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£ï¼‰"""
    if G.number_of_nodes() == 0:
        return {'modularity': 0, 'num_communities': 0}

    # Louvainæ³•ã§ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º
    communities = community.greedy_modularity_communities(G, weight='weight')

    # ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£è¨ˆç®—
    modularity = community.modularity(G, communities, weight='weight')

    # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚µã‚¤ã‚ºåˆ†å¸ƒ
    community_sizes = [len(c) for c in communities]

    return {
        'modularity': float(modularity),
        'num_communities': len(communities),
        'community_sizes': sorted(community_sizes, reverse=True),
        'communities': communities
    }

def evaluate_edge_weight_information(G: nx.Graph) -> Dict:
    """ã‚¨ãƒƒã‚¸é‡ã¿ã®æƒ…å ±é‡è©•ä¾¡"""
    if G.number_of_edges() == 0:
        return {'weight_variance': 0, 'weight_entropy': 0}

    weights = [data['weight'] for _, _, data in G.edges(data=True)]

    # é‡ã¿ã®åˆ†æ•£ï¼ˆå¤§ãã„ã»ã©æƒ…å ±é‡ãŒå¤šã„ï¼‰
    weight_variance = np.var(weights)

    # é‡ã¿ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆãƒ“ãƒ³åŒ–ã—ã¦è¨ˆç®—ï¼‰
    hist, _ = np.histogram(weights, bins=20)
    hist = hist / hist.sum()
    hist = hist[hist > 0]  # ã‚¼ãƒ­é™¤å¤–
    weight_entropy = -np.sum(hist * np.log2(hist))

    return {
        'weight_variance': float(weight_variance),
        'weight_entropy': float(weight_entropy),
        'weight_mean': float(np.mean(weights)),
        'weight_std': float(np.std(weights)),
        'weight_min': float(np.min(weights)),
        'weight_max': float(np.max(weights))
    }

def evaluate_graph_structure(G: nx.Graph, threshold: float) -> Dict:
    """ã‚°ãƒ©ãƒ•æ§‹é€ ã®ç·åˆè©•ä¾¡"""
    print(f"  è©•ä¾¡ä¸­: é–¾å€¤={threshold:.4f}, ãƒãƒ¼ãƒ‰={G.number_of_nodes()}, ã‚¨ãƒƒã‚¸={G.number_of_edges()}")

    # åŸºæœ¬çµ±è¨ˆ
    basic_stats = {
        'threshold': threshold,
        'num_nodes': G.number_of_nodes(),
        'num_edges': G.number_of_edges(),
        'density': nx.density(G) if G.number_of_nodes() > 0 else 0,
        'num_components': nx.number_connected_components(G)
    }

    # ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªè©•ä¾¡
    core_periphery = evaluate_core_periphery(G)

    # ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ è©•ä¾¡
    community_eval = evaluate_community_structure(G)

    # ã‚¨ãƒƒã‚¸é‡ã¿è©•ä¾¡
    edge_weight_eval = evaluate_edge_weight_information(G)

    # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆæ­£è¦åŒ–ã—ã¦åˆè¨ˆï¼‰
    # å„æŒ‡æ¨™ã‚’0-1ã«æ­£è¦åŒ–ã™ã‚‹ãŸã‚ã€å¾Œã§å…¨ä½“ã®æœ€å¤§å€¤ã§å‰²ã‚‹
    return {
        **basic_stats,
        'core_periphery': core_periphery,
        'community': community_eval,
        'edge_weight': edge_weight_eval
    }

def normalize_and_score(evaluations: List[Dict]) -> List[Dict]:
    """è©•ä¾¡çµæœã‚’æ­£è¦åŒ–ã—ã¦ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    # å„æŒ‡æ¨™ã®æœ€å¤§å€¤ã‚’å–å¾—
    max_cp_score = max([e['core_periphery']['score'] for e in evaluations if e['core_periphery']['score'] > 0], default=1)
    max_modularity = max([e['community']['modularity'] for e in evaluations], default=1)
    max_weight_var = max([e['edge_weight']['weight_variance'] for e in evaluations], default=1)

    for eval_result in evaluations:
        # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢
        cp_norm = eval_result['core_periphery']['score'] / max_cp_score if max_cp_score > 0 else 0
        mod_norm = eval_result['community']['modularity'] / max_modularity if max_modularity > 0 else 0
        weight_norm = eval_result['edge_weight']['weight_variance'] / max_weight_var if max_weight_var > 0 else 0

        # ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã«å¯¾ã™ã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£/å ±é…¬
        # ç†æƒ³çš„ãªã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’10-30ã¨ä»®å®š
        num_communities = eval_result['community']['num_communities']
        if 10 <= num_communities <= 30:
            cluster_score = 1.0
        elif num_communities < 10:
            # å°‘ãªã™ãã‚‹å ´åˆã¯ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆ3ã‚¯ãƒ©ã‚¹ã‚¿ãªã‚‰0.3ï¼‰
            cluster_score = num_communities / 10.0
        else:
            # å¤šã™ãã‚‹å ´åˆã‚‚ãƒšãƒŠãƒ«ãƒ†ã‚£
            cluster_score = max(0.5, 1.0 - (num_communities - 30) / 50.0)

        # ç·åˆã‚¹ã‚³ã‚¢ï¼ˆé‡ã¿ä»˜ã‘å¹³å‡ï¼‰
        # ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£ã¨ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’é‡è¦–
        total_score = 0.2 * cp_norm + 0.4 * mod_norm + 0.1 * weight_norm + 0.3 * cluster_score

        eval_result['normalized_scores'] = {
            'core_periphery': cp_norm,
            'modularity': mod_norm,
            'edge_weight': weight_norm,
            'cluster_count': cluster_score
        }
        eval_result['total_score'] = total_score

    return evaluations

def extract_cluster_center(G: nx.Graph, cluster: Set) -> str:
    """ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®ä¸­å¿ƒãƒãƒ¼ãƒ‰ã‚’ç‰¹å®šï¼ˆæ¬¡æ•°ã¨PageRankã®çµ„ã¿åˆã‚ã›ï¼‰"""
    subgraph = G.subgraph(cluster)

    if subgraph.number_of_nodes() == 0:
        return None

    # PageRankè¨ˆç®—
    try:
        pagerank = nx.pagerank(subgraph, weight='weight')
    except:
        pagerank = {node: 1.0 for node in subgraph.nodes()}

    # æ¬¡æ•°
    degrees = dict(subgraph.degree())

    # ã‚¹ã‚³ã‚¢ = PageRank * æ¬¡æ•°
    scores = {node: pagerank.get(node, 0) * degrees.get(node, 0) for node in subgraph.nodes()}

    # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ãƒãƒ¼ãƒ‰ã‚’è¿”ã™
    center = max(scores.keys(), key=lambda x: scores[x])
    return center

def analyze_clusters(G: nx.Graph, communities: List[Set], summaries_dict: Dict[str, str]) -> List[Dict]:
    """ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®è©³ç´°åˆ†æ"""
    cluster_info = []

    for i, cluster in enumerate(communities):
        cluster_nodes = list(cluster)

        # ä¸­å¿ƒãƒãƒ¼ãƒ‰ç‰¹å®š
        center_node = extract_cluster_center(G, cluster)

        # ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®å¹³å‡é¡ä¼¼åº¦
        subgraph = G.subgraph(cluster)
        if subgraph.number_of_edges() > 0:
            avg_similarity = np.mean([data['weight'] for _, _, data in subgraph.edges(data=True)])
        else:
            avg_similarity = 0

        # ã‚µãƒãƒªãƒ¼ãƒªã‚¹ãƒˆ
        intent_list = []
        for node in cluster_nodes:
            intent_list.append({
                'id': node,
                'summary': summaries_dict.get(node, ''),
                'is_center': node == center_node,
                'degree': subgraph.degree(node) if node in subgraph else 0
            })

        # æ¬¡æ•°ã§ã‚½ãƒ¼ãƒˆ
        intent_list.sort(key=lambda x: x['degree'], reverse=True)

        cluster_info.append({
            'cluster_id': i + 1,
            'size': len(cluster),
            'center_node': center_node,
            'center_summary': summaries_dict.get(center_node, ''),
            'avg_similarity': float(avg_similarity),
            'intents': intent_list
        })

    # ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºã§ã‚½ãƒ¼ãƒˆ
    cluster_info.sort(key=lambda x: x['size'], reverse=True)

    return cluster_info

def visualize_evaluation_comparison(evaluations: List[Dict], output_path: Path):
    """è©•ä¾¡çµæœã®æ¯”è¼ƒå¯è¦–åŒ–"""
    thresholds = [e['threshold'] for e in evaluations]

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªã‚¹ã‚³ã‚¢
    cp_scores = [e['core_periphery']['score'] for e in evaluations]
    axes[0, 0].plot(thresholds, cp_scores, marker='o', linewidth=2)
    axes[0, 0].set_xlabel('é–¾å€¤')
    axes[0, 0].set_ylabel('ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªã‚¹ã‚³ã‚¢')
    axes[0, 0].set_title('ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªæ§‹é€ ã®æ˜ç­æ€§')
    axes[0, 0].grid(alpha=0.3)

    # ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£
    modularities = [e['community']['modularity'] for e in evaluations]
    axes[0, 1].plot(thresholds, modularities, marker='o', linewidth=2, color='green')
    axes[0, 1].set_xlabel('é–¾å€¤')
    axes[0, 1].set_ylabel('ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£')
    axes[0, 1].set_title('ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ã®æ˜ç­æ€§')
    axes[0, 1].grid(alpha=0.3)

    # ã‚¨ãƒƒã‚¸é‡ã¿ã®åˆ†æ•£
    weight_vars = [e['edge_weight']['weight_variance'] for e in evaluations]
    axes[1, 0].plot(thresholds, weight_vars, marker='o', linewidth=2, color='red')
    axes[1, 0].set_xlabel('é–¾å€¤')
    axes[1, 0].set_ylabel('é‡ã¿ã®åˆ†æ•£')
    axes[1, 0].set_title('ã‚¨ãƒƒã‚¸é‡ã¿ã®æƒ…å ±é‡')
    axes[1, 0].grid(alpha=0.3)

    # ç·åˆã‚¹ã‚³ã‚¢
    total_scores = [e['total_score'] for e in evaluations]
    axes[1, 1].plot(thresholds, total_scores, marker='o', linewidth=2, color='purple')
    axes[1, 1].set_xlabel('é–¾å€¤')
    axes[1, 1].set_ylabel('ç·åˆã‚¹ã‚³ã‚¢')
    axes[1, 1].set_title('ç·åˆè©•ä¾¡ã‚¹ã‚³ã‚¢')
    axes[1, 1].grid(alpha=0.3)

    # æœ€é©ç‚¹ã‚’ãƒãƒ¼ã‚¯
    best_idx = total_scores.index(max(total_scores))
    best_threshold = thresholds[best_idx]
    axes[1, 1].axvline(best_threshold, color='orange', linestyle='--', label=f'æœ€é©: {best_threshold:.3f}')
    axes[1, 1].legend()

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

def visualize_cluster_internal_graph(
    G: nx.Graph,
    cluster_nodes: Set,
    cluster_id: int,
    summaries_dict: Dict[str, str],
    center_node: str,
    output_path: Path
):
    """ã‚¯ãƒ©ã‚¹ã‚¿å†…éƒ¨ã®ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–"""
    subgraph = G.subgraph(cluster_nodes)

    if subgraph.number_of_nodes() == 0:
        return

    fig, ax = plt.subplots(figsize=(16, 14))

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    pos = nx.spring_layout(subgraph, k=1.5, iterations=50, seed=42)

    # PageRankã‚’è¨ˆç®—
    try:
        pagerank = nx.pagerank(subgraph, weight='weight')
    except:
        pagerank = {node: 1.0 / subgraph.number_of_nodes() for node in subgraph.nodes()}

    # ãƒãƒ¼ãƒ‰ã®è‰²ã‚’PageRankã«åŸºã¥ã„ã¦ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    node_colors = [pagerank.get(node, 0) for node in subgraph.nodes()]

    # ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã¯æ¬¡æ•°ã«æ¯”ä¾‹
    node_sizes = [300 + 100 * subgraph.degree(node) for node in subgraph.nodes()]

    # ã‚¨ãƒƒã‚¸ã®é‡ã¿
    edges = subgraph.edges()
    weights = [subgraph[u][v]['weight'] for u, v in edges]

    # æç”»
    if weights:
        nx.draw_networkx_edges(
            subgraph, pos,
            width=[w * 3 for w in weights],
            alpha=0.4,
            edge_color=weights,
            edge_cmap=plt.cm.YlOrRd,
            edge_vmin=min(weights),
            edge_vmax=max(weights)
        )

    nx.draw_networkx_nodes(
        subgraph, pos,
        node_size=node_sizes,
        node_color=node_colors,
        cmap=plt.cm.YlOrRd,
        vmin=min(node_colors) if node_colors else 0,
        vmax=max(node_colors) if node_colors else 1,
        alpha=0.9,
        edgecolors='black',
        linewidths=2
    )

    # ãƒ©ãƒ™ãƒ«ï¼ˆæ”¹è¡Œå¯¾å¿œï¼‰
    labels = {}
    for node in subgraph.nodes():
        summary = summaries_dict.get(node, '')
        lines = []
        for i in range(0, len(summary), 15):
            lines.append(summary[i:i+15])
        labels[node] = '\n'.join(lines)

    nx.draw_networkx_labels(subgraph, pos, labels, font_size=8, font_family='Hiragino Sans')

    ax.set_title(
        f'ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_id} ã®å†…éƒ¨æ§‹é€ \n'
        f'ï¼ˆãƒãƒ¼ãƒ‰æ•°: {subgraph.number_of_nodes()}, ã‚¨ãƒƒã‚¸æ•°: {subgraph.number_of_edges()}ï¼‰',
        fontsize=14,
        fontweight='bold'
    )
    ax.axis('off')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

def build_meta_graph(
    G: nx.Graph,
    communities: List[Set],
    sim_matrix: np.ndarray,
    ids: List[str],
    summaries_dict: Dict[str, str]
) -> Tuple[nx.Graph, Dict]:
    """ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰"""
    id_to_idx = {id_: i for i, id_ in enumerate(ids)}
    meta_G = nx.Graph()
    cluster_info_meta = {}

    for i, cluster in enumerate(communities):
        cluster_id = i + 1
        cluster_nodes = list(cluster)

        subgraph = G.subgraph(cluster)
        if subgraph.number_of_edges() > 0:
            avg_similarity = np.mean([data['weight'] for _, _, data in subgraph.edges(data=True)])
        else:
            avg_similarity = 0

        if subgraph.number_of_nodes() > 0:
            try:
                pagerank = nx.pagerank(subgraph, weight='weight')
                center_node = max(pagerank.keys(), key=lambda x: pagerank[x])
                center_summary = summaries_dict.get(center_node, '')
            except:
                center_node = cluster_nodes[0]
                center_summary = summaries_dict.get(center_node, '')
        else:
            center_node = None
            center_summary = ''

        cluster_info_meta[cluster_id] = {
            'nodes': cluster_nodes,
            'size': len(cluster_nodes),
            'avg_similarity': avg_similarity,
            'center_summary': center_summary
        }

        meta_G.add_node(cluster_id, size=len(cluster_nodes), label=center_summary[:30])

    # ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®ã‚¨ãƒƒã‚¸ã‚’è¨ˆç®—
    for i, cluster_i in enumerate(communities):
        for j, cluster_j in enumerate(communities):
            if i >= j:
                continue

            cluster_id_i = i + 1
            cluster_id_j = j + 1

            similarities = []
            for node_i in cluster_i:
                for node_j in cluster_j:
                    idx_i = id_to_idx.get(node_i)
                    idx_j = id_to_idx.get(node_j)
                    if idx_i is not None and idx_j is not None:
                        similarities.append(sim_matrix[idx_i, idx_j])

            if similarities:
                avg_inter_similarity = np.mean(similarities)
                if avg_inter_similarity > 0.75:
                    meta_G.add_edge(
                        cluster_id_i,
                        cluster_id_j,
                        weight=avg_inter_similarity
                    )

    return meta_G, cluster_info_meta

def visualize_meta_graph(
    meta_G: nx.Graph,
    cluster_info_meta: Dict,
    output_path: Path
):
    """ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–"""
    fig, ax = plt.subplots(figsize=(20, 18))

    pos = nx.spring_layout(meta_G, k=4, iterations=100, seed=42)

    try:
        meta_pagerank = nx.pagerank(meta_G, weight='weight')
    except:
        meta_pagerank = {node: 1.0 / meta_G.number_of_nodes() for node in meta_G.nodes()}

    node_sizes = [cluster_info_meta[node]['size'] * 150 for node in meta_G.nodes()]
    node_colors = [meta_pagerank.get(node, 0) for node in meta_G.nodes()]

    if meta_G.number_of_edges() > 0:
        edges = meta_G.edges()
        weights = [meta_G[u][v]['weight'] for u, v in edges]

        nx.draw_networkx_edges(
            meta_G, pos,
            width=[w * 5 for w in weights],
            alpha=0.4,
            edge_color='gray'
        )

    nx.draw_networkx_nodes(
        meta_G, pos,
        node_size=node_sizes,
        node_color=node_colors,
        cmap=plt.cm.YlOrRd,
        vmin=min(node_colors) if node_colors else 0,
        vmax=max(node_colors) if node_colors else 1,
        alpha=0.9,
        edgecolors='black',
        linewidths=2
    )

    labels = {}
    for node in meta_G.nodes():
        size = cluster_info_meta[node]['size']
        labels[node] = f"C{node}\n({size}ä»¶)"

    nx.draw_networkx_labels(meta_G, pos, labels, font_size=10, font_weight='bold')

    for node, (x, y) in pos.items():
        summary = cluster_info_meta[node]['center_summary']
        lines = []
        for i in range(0, len(summary), 12):
            lines.append(summary[i:i+12])
        if len(lines) > 3:
            lines = lines[:3]
            lines[-1] = lines[-1][:9] + '...'

        formatted_summary = '\n'.join(lines)

        ax.text(
            x, y - 0.12,
            formatted_summary,
            fontsize=8,
            ha='center',
            bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5)
        )

    ax.set_title(
        f'ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®é–¢ä¿‚ï¼ˆãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ï¼‰\n'
        f'ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {meta_G.number_of_nodes()}, ã‚¯ãƒ©ã‚¹ã‚¿é–“æ¥ç¶š: {meta_G.number_of_edges()}',
        fontsize=14,
        fontweight='bold'
    )
    ax.axis('off')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

def create_cluster_report(
    best_evaluation: Dict,
    cluster_info: List[Dict],
    all_evaluations: List[Dict],
    meta_graph_stats: Dict,
    output_path: Path
):
    """ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’HTMLã§ä½œæˆ"""
    best_threshold = best_evaluation['threshold']

    html_content = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{
            font-family: 'Hiragino Sans', 'Hiragino Kaku Gothic ProN', sans-serif;
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        h1 {{
            color: #333;
            border-bottom: 3px solid #4CAF50;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #555;
            border-bottom: 2px solid #2196F3;
            padding-bottom: 8px;
            margin-top: 30px;
        }}
        h3 {{
            color: #666;
            margin-top: 20px;
        }}
        .section {{
            background-color: white;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
        }}
        th, td {{
            padding: 12px;
            text-align: left;
            border-bottom: 1px solid #ddd;
        }}
        th {{
            background-color: #4CAF50;
            color: white;
            font-weight: bold;
        }}
        tr:hover {{
            background-color: #f5f5f5;
        }}
        .cluster {{
            background-color: #f9f9f9;
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            border-left: 5px solid #FF9800;
        }}
        .cluster-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }}
        .cluster-title {{
            font-size: 1.3em;
            font-weight: bold;
            color: #333;
        }}
        .cluster-size {{
            background-color: #FF9800;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: bold;
        }}
        .center-intent {{
            background-color: #E3F2FD;
            padding: 15px;
            border-radius: 5px;
            margin: 10px 0;
            border-left: 4px solid #2196F3;
        }}
        .center-label {{
            font-weight: bold;
            color: #1976D2;
            font-size: 0.9em;
            margin-bottom: 5px;
        }}
        .intent-list {{
            margin-top: 15px;
        }}
        .intent-item {{
            background-color: white;
            padding: 10px;
            margin: 5px 0;
            border-radius: 3px;
            border-left: 3px solid #4CAF50;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}
        .intent-item:hover {{
            background-color: #f0f0f0;
        }}
        .intent-id {{
            font-size: 0.85em;
            color: #666;
            font-family: monospace;
        }}
        .intent-degree {{
            background-color: #4CAF50;
            color: white;
            padding: 3px 10px;
            border-radius: 15px;
            font-size: 0.85em;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }}
        .stat-box {{
            background-color: #e3f2fd;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #2196F3;
        }}
        .stat-label {{
            font-weight: bold;
            color: #555;
            font-size: 0.9em;
        }}
        .stat-value {{
            font-size: 1.5em;
            color: #1976D2;
            margin-top: 5px;
        }}
        img {{
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            margin: 15px 0;
        }}
        .best-indicator {{
            background-color: #FFD700;
            color: #333;
            padding: 5px 10px;
            border-radius: 3px;
            font-weight: bold;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <h1>ğŸ¯ ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>

    <div class="section">
        <h2>1. æœ€é©ã‚°ãƒ©ãƒ•ã®é¸å®š</h2>
        <p>ä»¥ä¸‹ã®3ã¤ã®è©•ä¾¡åŸºæº–ã«åŸºã¥ã„ã¦æœ€é©ãªé¡ä¼¼åº¦é–¾å€¤ã‚’é¸å®šã—ã¾ã—ãŸï¼š</p>
        <ul>
            <li><strong>ã‚³ã‚¢-ãƒšãƒªãƒ•ã‚§ãƒªæ§‹é€ ï¼š</strong> ä¸­å¿ƒçš„ãªãƒãƒ¼ãƒ‰ã¨å‘¨è¾ºãƒãƒ¼ãƒ‰ã®æ˜ç¢ºãªåŒºåˆ¥</li>
            <li><strong>ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ï¼ˆãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£ï¼‰ï¼š</strong> æ„å‘³çš„ã«ã¾ã¨ã¾ã£ãŸã‚¯ãƒ©ã‚¹ã‚¿ã®å½¢æˆ</li>
            <li><strong>ã‚¨ãƒƒã‚¸é‡ã¿ã®æƒ…å ±é‡ï¼š</strong> é¡ä¼¼åº¦ã®å¤šæ§˜æ€§ï¼ˆåˆ†æ•£ï¼‰</li>
        </ul>

        <h3>è©•ä¾¡çµæœã®æ¯”è¼ƒ</h3>
        <img src="evaluation_comparison.png" alt="è©•ä¾¡æŒ‡æ¨™ã®æ¯”è¼ƒ">

        <h3>é¸å®šã•ã‚ŒãŸæœ€é©é–¾å€¤</h3>
        <div class="stats">
            <div class="stat-box">
                <div class="stat-label">æœ€é©é–¾å€¤</div>
                <div class="stat-value">{best_threshold:.4f}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">ç·åˆã‚¹ã‚³ã‚¢</div>
                <div class="stat-value">{best_evaluation['total_score']:.4f}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">æ¤œå‡ºã‚¯ãƒ©ã‚¹ã‚¿æ•°</div>
                <div class="stat-value">{best_evaluation['community']['num_communities']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£</div>
                <div class="stat-value">{best_evaluation['community']['modularity']:.4f}</div>
            </div>
        </div>

        <h3>è©³ç´°è©•ä¾¡æŒ‡æ¨™</h3>
        <table>
            <tr>
                <th>æŒ‡æ¨™</th>
                <th>å€¤</th>
                <th>èª¬æ˜</th>
            </tr>
            <tr>
                <td>ãƒãƒ¼ãƒ‰æ•°</td>
                <td>{best_evaluation['num_nodes']}</td>
                <td>ã‚°ãƒ©ãƒ•å†…ã®ç·ãƒãƒ¼ãƒ‰æ•°</td>
            </tr>
            <tr>
                <td>ã‚¨ãƒƒã‚¸æ•°</td>
                <td>{best_evaluation['num_edges']}</td>
                <td>ã‚°ãƒ©ãƒ•å†…ã®ç·ã‚¨ãƒƒã‚¸æ•°</td>
            </tr>
            <tr>
                <td>ã‚°ãƒ©ãƒ•å¯†åº¦</td>
                <td>{best_evaluation['density']:.4f}</td>
                <td>å®Ÿéš›ã®ã‚¨ãƒƒã‚¸æ•° / å¯èƒ½ãªæœ€å¤§ã‚¨ãƒƒã‚¸æ•°</td>
            </tr>
            <tr>
                <td>é€£çµæˆåˆ†æ•°</td>
                <td>{best_evaluation['num_components']}</td>
                <td>åˆ†é›¢ã—ãŸã‚µãƒ–ã‚°ãƒ©ãƒ•ã®æ•°</td>
            </tr>
            <tr>
                <td>ã‚³ã‚¢ãƒãƒ¼ãƒ‰æ•°</td>
                <td>{best_evaluation['core_periphery']['core_size']}</td>
                <td>é«˜æ¬¡æ•°ã‚’æŒã¤ä¸­å¿ƒçš„ãƒãƒ¼ãƒ‰æ•°</td>
            </tr>
            <tr>
                <td>ãƒšãƒªãƒ•ã‚§ãƒªãƒãƒ¼ãƒ‰æ•°</td>
                <td>{best_evaluation['core_periphery']['periphery_size']}</td>
                <td>ä½æ¬¡æ•°ã‚’æŒã¤å‘¨è¾ºãƒãƒ¼ãƒ‰æ•°</td>
            </tr>
            <tr>
                <td>ã‚¨ãƒƒã‚¸é‡ã¿å¹³å‡</td>
                <td>{best_evaluation['edge_weight']['weight_mean']:.4f}</td>
                <td>é¡ä¼¼åº¦ã®å¹³å‡å€¤</td>
            </tr>
            <tr>
                <td>ã‚¨ãƒƒã‚¸é‡ã¿åˆ†æ•£</td>
                <td>{best_evaluation['edge_weight']['weight_variance']:.6f}</td>
                <td>é¡ä¼¼åº¦ã®ã°ã‚‰ã¤ã</td>
            </tr>
        </table>
    </div>

    <div class="section">
        <h2>2. ã‚¯ãƒ©ã‚¹ã‚¿ä¸€è¦§ï¼ˆã‚µã‚¤ã‚ºé †ï¼‰</h2>
        <p>æ¤œå‡ºã•ã‚ŒãŸå…¨{len(cluster_info)}ã‚¯ãƒ©ã‚¹ã‚¿ã®æ¦‚è¦ã§ã™ã€‚å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ä¸­å¿ƒã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’åŸºæº–ã«æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>

        <table>
            <tr>
                <th>ã‚¯ãƒ©ã‚¹ã‚¿ID</th>
                <th>ã‚µã‚¤ã‚º</th>
                <th>ä¸­å¿ƒã‚¤ãƒ³ãƒ†ãƒ³ãƒˆ</th>
                <th>å¹³å‡é¡ä¼¼åº¦</th>
            </tr>
"""

    for cluster in cluster_info:
        html_content += f"""
            <tr>
                <td><strong>ã‚¯ãƒ©ã‚¹ã‚¿ {cluster['cluster_id']}</strong></td>
                <td>{cluster['size']}</td>
                <td>{cluster['center_summary']}</td>
                <td>{cluster['avg_similarity']:.4f}</td>
            </tr>
"""

    html_content += """
        </table>
    </div>

    <div class="section">
        <h2>3. ã‚¯ãƒ©ã‚¹ã‚¿è©³ç´°</h2>
        <p>å„ã‚¯ãƒ©ã‚¹ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã®ä¸€è¦§ã§ã™ã€‚ä¸­å¿ƒã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã¯é’è‰²ã§å¼·èª¿è¡¨ç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
"""

    for cluster in cluster_info:
        html_content += f"""
        <div class="cluster">
            <div class="cluster-header">
                <div class="cluster-title">ğŸ“ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster['cluster_id']}</div>
                <div class="cluster-size">{cluster['size']}ä»¶</div>
            </div>

            <div class="center-intent">
                <div class="center-label">â­ ä¸­å¿ƒã‚¤ãƒ³ãƒ†ãƒ³ãƒˆ</div>
                <div><strong>{cluster['center_node']}:</strong> {cluster['center_summary']}</div>
                <div style="margin-top: 5px; font-size: 0.9em; color: #666;">
                    å¹³å‡é¡ä¼¼åº¦: {cluster['avg_similarity']:.4f}
                </div>
            </div>

            <div class="intent-list">
                <h4>å«ã¾ã‚Œã‚‹ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆï¼ˆæ¬¡æ•°é †ï¼‰</h4>
"""

        for intent in cluster['intents']:
            center_mark = " â­" if intent['is_center'] else ""
            html_content += f"""
                <div class="intent-item">
                    <div>
                        <div>{intent['summary']}{center_mark}</div>
                        <div class="intent-id">{intent['id']}</div>
                    </div>
                    <div class="intent-degree">æ¬¡æ•°: {intent['degree']}</div>
                </div>
"""

        html_content += """
            </div>
        </div>
"""

    html_content += f"""
    </div>

    <div class="section">
        <h2>4. ä»–ã®é–¾å€¤ã¨ã®æ¯”è¼ƒ</h2>
        <p>ç•°ãªã‚‹é–¾å€¤ã§ã®è©•ä¾¡çµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚</p>

        <table>
            <tr>
                <th>é–¾å€¤</th>
                <th>ç·åˆã‚¹ã‚³ã‚¢</th>
                <th>ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£</th>
                <th>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</th>
                <th>ã‚¨ãƒƒã‚¸æ•°</th>
            </tr>
"""

    for eval_result in sorted(all_evaluations, key=lambda x: x['total_score'], reverse=True):
        is_best = eval_result['threshold'] == best_threshold
        best_mark = '<span class="best-indicator">â˜… æœ€é©</span>' if is_best else ''
        html_content += f"""
            <tr style="{'background-color: #FFF9C4;' if is_best else ''}">
                <td><strong>{eval_result['threshold']:.4f}</strong> {best_mark}</td>
                <td>{eval_result['total_score']:.4f}</td>
                <td>{eval_result['community']['modularity']:.4f}</td>
                <td>{eval_result['community']['num_communities']}</td>
                <td>{eval_result['num_edges']}</td>
            </tr>
"""

    html_content += f"""
        </table>
    </div>

    <div class="section">
        <h2>5. ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®é–¢ä¿‚ï¼ˆãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ï¼‰</h2>
        <p>å„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’ãƒãƒ¼ãƒ‰ã¨ã—ã¦ã€ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®å¹³å‡é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦æ¥ç¶šã—ãŸãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã§ã™ã€‚</p>

        <img src="meta_graph.png" alt="ã‚¯ãƒ©ã‚¹ã‚¿é–“ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•">

        <h3>ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆ</h3>
        <div class="stats">
            <div class="stat-box">
                <div class="stat-label">ã‚¯ãƒ©ã‚¹ã‚¿ç·æ•°</div>
                <div class="stat-value">{meta_graph_stats['num_clusters']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">ã‚¯ãƒ©ã‚¹ã‚¿é–“æ¥ç¶šæ•°</div>
                <div class="stat-value">{meta_graph_stats['num_edges']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">å­¤ç«‹ã‚¯ãƒ©ã‚¹ã‚¿æ•°</div>
                <div class="stat-value">{meta_graph_stats['num_isolated']}</div>
            </div>
            <div class="stat-box">
                <div class="stat-label">å¹³å‡ã‚¯ãƒ©ã‚¹ã‚¿é–“é¡ä¼¼åº¦</div>
                <div class="stat-value">{meta_graph_stats['avg_inter_similarity']:.4f}</div>
            </div>
        </div>

        <h3>è§£é‡ˆ</h3>
        <ul>
            <li><strong>ãƒãƒ¼ãƒ‰ã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</strong>: PageRankï¼ˆä¸­å¿ƒæ€§ï¼‰ã‚’è¡¨ã™ï¼ˆèµ¤=é‡è¦ã€é»„=å‘¨è¾ºï¼‰</li>
            <li><strong>ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º</strong>: ã‚¯ãƒ©ã‚¹ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæ•°ã«æ¯”ä¾‹</li>
            <li><strong>ã‚¨ãƒƒã‚¸ã®å¤ªã•</strong>: ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®å¹³å‡é¡ä¼¼åº¦ã«æ¯”ä¾‹</li>
            <li><strong>æœ€ã‚‚èµ¤ã„ã‚¯ãƒ©ã‚¹ã‚¿</strong>: å¤šãã®ã‚¯ãƒ©ã‚¹ã‚¿ã¨é–¢é€£ã™ã‚‹ä¸­å¿ƒçš„ãªãƒˆãƒ”ãƒƒã‚¯</li>
        </ul>
    </div>

    <div class="section">
        <h2>6. ä¸»è¦ã‚¯ãƒ©ã‚¹ã‚¿ã®å†…éƒ¨æ§‹é€ </h2>
        <p>ã‚µã‚¤ã‚ºã®å¤§ãã„ä¸Šä½5ã‚¯ãƒ©ã‚¹ã‚¿ã«ã¤ã„ã¦ã€å†…éƒ¨ã®ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’å¯è¦–åŒ–ã—ã¾ã—ãŸã€‚</p>
"""

    # ä¸Šä½5ã‚¯ãƒ©ã‚¹ã‚¿
    for i, cluster in enumerate(cluster_info[:5]):
        html_content += f"""
        <h3>ã‚¯ãƒ©ã‚¹ã‚¿ {cluster['cluster_id']}ï¼ˆ{cluster['size']}ä»¶ï¼‰</h3>
        <p><strong>ä¸­å¿ƒãƒ†ãƒ¼ãƒ:</strong> {cluster['center_summary']}</p>
        <img src="cluster_{cluster['cluster_id']}_internal.png" alt="ã‚¯ãƒ©ã‚¹ã‚¿{cluster['cluster_id']}å†…éƒ¨æ§‹é€ ">
"""

    html_content += """
        <h3>å†…éƒ¨ã‚°ãƒ©ãƒ•ã®è¦‹æ–¹</h3>
        <ul>
            <li><strong>ãƒãƒ¼ãƒ‰ã®è‰²ï¼ˆã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰</strong>: PageRankï¼ˆä¸­å¿ƒæ€§ï¼‰ã‚’è¡¨ã™ï¼ˆèµ¤=ä¸­å¿ƒã€é»„=å‘¨è¾ºï¼‰</li>
            <li><strong>ãƒãƒ¼ãƒ‰ã‚µã‚¤ã‚º</strong>: ã‚¯ãƒ©ã‚¹ã‚¿å†…ã§ã®æ¥ç¶šæ•°ï¼ˆæ¬¡æ•°ï¼‰ã«æ¯”ä¾‹</li>
            <li><strong>ã‚¨ãƒƒã‚¸ã®å¤ªã•ãƒ»è‰²</strong>: é¡ä¼¼åº¦ï¼ˆèµ¤=é«˜ã€é»„=ä½ï¼‰</li>
        </ul>
    </div>

    <div class="section">
        <h2>7. ç”Ÿæˆæ—¥æ™‚</h2>
        <p>{pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
    </div>

</body>
</html>
"""

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

def main():
    print("=" * 60)
    print("ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\n[1/7] åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    input_file = "output/intents_embedded.json"
    data, embeddings, ids, summaries = load_embeddings(input_file)
    summaries_dict = dict(zip(ids, summaries))
    print(f"  âœ“ {len(ids)}å€‹ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # é¡ä¼¼åº¦è¡Œåˆ—è¨ˆç®—
    print("\n[2/7] é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—ä¸­...")
    sim_matrix = compute_similarity_matrix(embeddings)
    print(f"  âœ“ {sim_matrix.shape[0]}x{sim_matrix.shape[1]}ã®é¡ä¼¼åº¦è¡Œåˆ—ã‚’ç”Ÿæˆ")

    # è¤‡æ•°é–¾å€¤ã§ã‚°ãƒ©ãƒ•ç”Ÿæˆã¨è©•ä¾¡
    print("\n[3/7] è¤‡æ•°é–¾å€¤ã§ã‚°ãƒ©ãƒ•ã‚’è©•ä¾¡ä¸­...")

    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«å€¤ã‚’å–å¾—
    triu_indices = np.triu_indices_from(sim_matrix, k=1)
    similarities = sim_matrix[triu_indices]

    # è©•ä¾¡ã™ã‚‹é–¾å€¤ï¼ˆ85%ã€œ99.5%ã«ç¯„å›²ã‚’æ‹¡å¼µã—ã€ã‚ˆã‚Šç´°ã‹ãè©•ä¾¡ï¼‰
    percentiles = [85, 87, 89, 90, 92, 94, 95, 96, 97, 98, 99, 99.5]
    thresholds = [np.percentile(similarities, p) for p in percentiles]

    print(f"  è©•ä¾¡ç¯„å›²: {thresholds[0]:.4f} - {thresholds[-1]:.4f}")

    evaluations = []
    for threshold in thresholds:
        relations = extract_relations(sim_matrix, ids, threshold)
        G = build_graph(relations)
        evaluation = evaluate_graph_structure(G, threshold)
        evaluations.append(evaluation)

    # æ­£è¦åŒ–ã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    print("\n[4/7] ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ä¸­...")
    evaluations = normalize_and_score(evaluations)

    # æœ€é©ã‚°ãƒ©ãƒ•ã‚’é¸å®š
    best_evaluation = max(evaluations, key=lambda x: x['total_score'])
    best_threshold = best_evaluation['threshold']
    print(f"  âœ“ æœ€é©é–¾å€¤: {best_threshold:.4f}")
    print(f"  âœ“ ç·åˆã‚¹ã‚³ã‚¢: {best_evaluation['total_score']:.4f}")
    print(f"  âœ“ ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£: {best_evaluation['community']['modularity']:.4f}")
    print(f"  âœ“ ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {best_evaluation['community']['num_communities']}")

    # æœ€é©ã‚°ãƒ©ãƒ•ã‚’å†æ§‹ç¯‰
    print("\n[5/7] æœ€é©ã‚°ãƒ©ãƒ•ã§ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æä¸­...")
    relations = extract_relations(sim_matrix, ids, best_threshold)
    G = build_graph(relations)

    # ã‚¯ãƒ©ã‚¹ã‚¿æƒ…å ±ã‚’æŠ½å‡º
    communities = best_evaluation['community']['communities']
    cluster_info = analyze_clusters(G, communities, summaries_dict)
    print(f"  âœ“ {len(cluster_info)}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’æŠ½å‡º")
    print(f"  âœ“ æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º: {cluster_info[0]['size']}")

    # è©•ä¾¡æ¯”è¼ƒã®å¯è¦–åŒ–
    print("\n[6/7] è©•ä¾¡çµæœã‚’å¯è¦–åŒ–ä¸­...")
    visualize_evaluation_comparison(evaluations, OUTPUT_DIR / "evaluation_comparison.png")
    print("  âœ“ å¯è¦–åŒ–å®Œäº†")

    # ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•æ§‹ç¯‰ã¨å¯è¦–åŒ–
    print("\n[7/10] ã‚¯ãƒ©ã‚¹ã‚¿é–“ã®ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ä¸­...")
    meta_G, cluster_info_meta = build_meta_graph(G, communities, sim_matrix, ids, summaries_dict)
    print(f"  âœ“ ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•: {meta_G.number_of_nodes()}ãƒãƒ¼ãƒ‰, {meta_G.number_of_edges()}ã‚¨ãƒƒã‚¸")

    print("\n[8/10] ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–ä¸­...")
    visualize_meta_graph(meta_G, cluster_info_meta, OUTPUT_DIR / "meta_graph.png")
    print("  âœ“ ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•å¯è¦–åŒ–å®Œäº†")

    # ä¸»è¦ã‚¯ãƒ©ã‚¹ã‚¿ã®å†…éƒ¨ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–
    print("\n[9/10] ä¸»è¦ã‚¯ãƒ©ã‚¹ã‚¿ã®å†…éƒ¨æ§‹é€ ã‚’å¯è¦–åŒ–ä¸­...")
    for i, cluster in enumerate(cluster_info[:5]):
        cluster_nodes = set([item['id'] for item in cluster['intents']])
        visualize_cluster_internal_graph(
            G, cluster_nodes, cluster['cluster_id'], summaries_dict,
            cluster['center_node'],
            OUTPUT_DIR / f"cluster_{cluster['cluster_id']}_internal.png"
        )
        print(f"  âœ“ ã‚¯ãƒ©ã‚¹ã‚¿ {cluster['cluster_id']} å¯è¦–åŒ–å®Œäº†")

    # ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•ã®çµ±è¨ˆ
    meta_graph_stats = {
        'num_clusters': meta_G.number_of_nodes(),
        'num_edges': meta_G.number_of_edges(),
        'num_isolated': len(list(nx.isolates(meta_G))),
        'avg_inter_similarity': np.mean([data['weight'] for _, _, data in meta_G.edges(data=True)]) if meta_G.number_of_edges() > 0 else 0
    }

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("\n[10/10] çµ±åˆã‚¯ãƒ©ã‚¹ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    create_cluster_report(
        best_evaluation,
        cluster_info,
        evaluations,
        meta_graph_stats,
        OUTPUT_DIR / "cluster_report.html"
    )
    print("  âœ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")

    print("\n" + "=" * 60)
    print("âœ… åˆ†æå®Œäº†ï¼")
    print("=" * 60)
    print(f"\nğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
    print(f"ğŸ“„ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ: {OUTPUT_DIR / 'cluster_report.html'}")
    print(f"ğŸ“Š ãƒ¡ã‚¿ã‚°ãƒ©ãƒ•: {OUTPUT_DIR / 'meta_graph.png'}")
    print(f"ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿å†…éƒ¨ã‚°ãƒ©ãƒ•: cluster_X_internal.png (X=1-5)")
    print("\nãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ã„ã¦çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
