#!/usr/bin/env python3
"""
ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ

Gemini Embedding APIã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ™ã‚¯ãƒˆãƒ«åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
"""

import json
import os
import hashlib
from pathlib import Path
import pandas as pd
from dotenv import load_dotenv
import google.generativeai as genai
from tqdm import tqdm
from app.cache import get_cache

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


def generate_embedding(text: str, cache) -> list[float]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰

    Args:
        text: åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        cache: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

    Returns:
        åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆ768æ¬¡å…ƒï¼‰
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ
    cache_key = hashlib.md5(text.encode('utf-8')).hexdigest()

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
    cached_result = cache.get(cache_key)
    if cached_result is not None:
        return cached_result

    # Gemini Embedding APIå‘¼ã³å‡ºã—
    try:
        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="clustering"
        )
        embedding = result['embedding']

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        cache.set(cache_key, embedding)

        return embedding
    except Exception as e:
        print(f"  ! åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¿”ã™
        return [0.0] * 768


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ")
    print("=" * 60)

    # å…¥åŠ›CSVãƒ‘ã‚¹
    csv_path = "/Users/mikke/git_dir/chat-line/output/db-exports/2025-11-10T23-54-08/messages_with_hierarchy.csv"

    # CSVèª­ã¿è¾¼ã¿
    print(f"\nCSVã‚’èª­ã¿è¾¼ã¿ä¸­: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ“ {len(df)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    # message_idã‚’ç”Ÿæˆï¼ˆmessage_clustering.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    df['message_id'] = [f"msg_{i:05d}" for i in range(len(df))]

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–
    cache = get_cache("embeddings")

    # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
    print("\nåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­...")
    embeddings_data = []

    for _, row in tqdm(df.iterrows(), total=len(df), desc="Generating embeddings"):
        msg_id = row['message_id']
        text = row['combined_content']

        # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if pd.isna(text) or str(text).strip() == "":
            print(f"  ! ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {msg_id} ã¯ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            continue

        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        embedding = generate_embedding(str(text), cache)

        embeddings_data.append({
            'id': msg_id,
            'embedding': embedding
        })

    # JSONä¿å­˜
    output_path = OUTPUT_DIR / "messages_embedded.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(embeddings_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ åŸ‹ã‚è¾¼ã¿ã‚’ä¿å­˜: {output_path}")
    print(f"  - ä»¶æ•°: {len(embeddings_data)}")
    print(f"  - æ¬¡å…ƒæ•°: {len(embeddings_data[0]['embedding']) if embeddings_data else 0}")

    print("\n" + "=" * 60)
    print("âœ… åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†ï¼")
    print("=" * 60)
    print(f"ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  uv run python message_clustering.py")


if __name__ == "__main__":
    main()
