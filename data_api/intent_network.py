#!/usr/bin/env python3
"""
ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ã‚·ã‚¹ãƒ†ãƒ 

æŠ½å‡ºã•ã‚ŒãŸã‚¤ãƒ³ãƒ†ãƒ³ãƒˆé–“ã®é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’æ§‹ç¯‰ã—ã€
ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªHTMLã§å¯è¦–åŒ–ã™ã‚‹ã€‚

ä¸»ãªæ©Ÿèƒ½:
1. è¤‡æ•°ã®cluster_XX_processed.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿
2. ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
3. é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ã‚¨ãƒƒã‚¸ã‚’æ§‹ç¯‰
4. ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªHTMLãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
"""

import json
import hashlib
import numpy as np
import pandas as pd
from pathlib import Path
import warnings
from dotenv import load_dotenv
from tqdm import tqdm
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pyvis.network import Network
import networkx as nx

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥
from app.cache import get_cache

warnings.filterwarnings('ignore')

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
OUTPUT_DIR = Path("output/intent_network")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


class IntentNetworkBuilder:
    """ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰"""

    def __init__(
        self,
        input_dir: Path,
        model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        similarity_threshold: float = 0.7,
        max_edges_per_node: int = 5,
    ):
        """
        Args:
            input_dir: ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæŠ½å‡ºçµæœã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            model_name: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
            similarity_threshold: ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã™ã‚‹æœ€å°é¡ä¼¼åº¦
            max_edges_per_node: å„ãƒãƒ¼ãƒ‰ã‹ã‚‰ä¼¸ã³ã‚‹æœ€å¤§ã‚¨ãƒƒã‚¸æ•°
        """
        self.input_dir = Path(input_dir)
        self.model_name = model_name
        self.similarity_threshold = similarity_threshold
        self.max_edges_per_node = max_edges_per_node

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.df = self._load_all_intents()
        self._preprocess_dataframe()

        # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
        self.embeddings = None
        self.embedding_dim = None
        self._generate_embeddings()

    def _load_all_intents(self) -> pd.DataFrame:
        """å…¨ã¦ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        all_intents = []
        json_files = sorted(self.input_dir.glob("cluster_*_processed.json"))

        print(f"ğŸ“‚ {len(json_files)}å€‹ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        for json_file in json_files:
            with open(json_file, 'r', encoding='utf-8') as f:
                intents = json.load(f)

            for intent_data in intents:
                # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ¬ ã‘ã¦ã„ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰
                record = {
                    'intent': intent_data.get('intent', ''),
                    'status': intent_data.get('status', 'unknown'),
                    'objective_facts': intent_data.get('objective_facts', ''),
                    'context': intent_data.get('context', ''),
                    'source_message_ids': ','.join(intent_data.get('source_message_ids', [])),
                    'original_cluster_id': intent_data.get('cluster_id', -1),
                    'source_full_paths': ','.join(intent_data.get('source_full_paths', [])),
                    'min_start_timestamp': intent_data.get('min_start_timestamp', '1970-01-01T00:00:00'),
                }
                all_intents.append(record)

        df = pd.DataFrame(all_intents)
        print(f"âœ“ {len(df)}ä»¶ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return df

    def _preprocess_dataframe(self):
        """DataFrameã®å‰å‡¦ç†"""
        # æ™‚åˆ»ã‚’datetimeã«å¤‰æ›
        self.df['start_time'] = pd.to_datetime(self.df['min_start_timestamp'])

        # ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆIDã‚’ç”Ÿæˆï¼ˆè¡Œç•ªå·ãƒ™ãƒ¼ã‚¹ï¼‰
        self.df['intent_id'] = [f"intent_{i:05d}" for i in range(len(self.df))]

        # ãƒ‘ã‚¹å‡¦ç†: source_full_pathsã‹ã‚‰æœ€åˆã®ãƒ‘ã‚¹ã‚’æŠ½å‡º
        def extract_first_path(paths_str: str) -> str:
            if pd.isna(paths_str) or paths_str == '':
                return 'Unknown'
            paths = paths_str.split(',')
            return paths[0].strip() if paths else 'Unknown'

        self.df['full_path'] = self.df['source_full_paths'].apply(extract_first_path)

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥é›†è¨ˆ
        status_counts = self.df['status'].value_counts()
        print(f"  - æœŸé–“: {self.df['start_time'].min()} ã€œ {self.df['start_time'].max()}")
        print(f"  - ãƒ‘ã‚¹æ•°: {self.df['full_path'].nunique()}")
        print(f"  - ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥: {dict(status_counts)}")

    def _generate_embeddings(self):
        """åŸ‹ã‚è¾¼ã¿ã®ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨ï¼‰"""
        print(f"ğŸ”„ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­ï¼ˆãƒ¢ãƒ‡ãƒ«: {self.model_name}ï¼‰...")

        cache = get_cache("intent_network_embeddings")
        model = SentenceTransformer(self.model_name)

        embeddings_list = []

        # é™¤å¤–ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
        exclude_fields = {
            'source_message_ids', 'original_cluster_id', 'source_full_paths',
            'min_start_timestamp', 'intent_id', 'start_time', 'full_path'
        }

        for idx, row in tqdm(self.df.iterrows(), total=len(self.df), desc="åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"):
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã®å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’çµåˆã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
            text_parts = []
            for field, value in row.items():
                if field not in exclude_fields and pd.notna(value) and str(value).strip():
                    text_parts.append(str(value))

            text = " ".join(text_parts)
            cache_key = f"intent_embedding:{self.model_name}:{hashlib.md5(text.encode()).hexdigest()}"

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
            cached_embedding = cache.get(cache_key)
            if cached_embedding is not None:
                embedding = np.array(cached_embedding)
            else:
                # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
                embedding = model.encode(text, convert_to_numpy=True)
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                cache.set(cache_key, embedding.tolist())

            embeddings_list.append(embedding)

        self.embeddings = np.array(embeddings_list)
        self.embedding_dim = self.embeddings.shape[1]
        print(f"âœ“ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆå®Œäº†ï¼ˆæ¬¡å…ƒ: {self.embedding_dim}ï¼‰")

    def build_network(self) -> nx.Graph:
        """é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ§‹ç¯‰"""
        print(f"ğŸ”— ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰ä¸­ï¼ˆé¡ä¼¼åº¦é–¾å€¤: {self.similarity_threshold}ï¼‰...")

        # é¡ä¼¼åº¦è¡Œåˆ—ã‚’è¨ˆç®—
        similarity_matrix = cosine_similarity(self.embeddings)

        # NetworkXã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
        G = nx.Graph()

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        for idx, row in self.df.iterrows():
            node_id = row['intent_id']
            G.add_node(
                node_id,
                intent=row['intent'],
                status=row['status'],
                objective_facts=row['objective_facts'],
                context=row['context'],
                full_path=row['full_path'],
                start_time=row['start_time'].strftime('%Y-%m-%d %H:%M'),
                original_cluster=row['original_cluster_id']
            )

        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆé¡ä¼¼åº¦ãŒé–¾å€¤ä»¥ä¸Šã®ãƒšã‚¢ï¼‰
        edge_count = 0
        for i in range(len(self.df)):
            # å„ãƒãƒ¼ãƒ‰ã«ã¤ã„ã¦ã€é¡ä¼¼åº¦ãŒé«˜ã„ä¸Šä½Nå€‹ã¨ã‚¨ãƒƒã‚¸ã‚’ä½œæˆ
            similarities = similarity_matrix[i]
            # è‡ªåˆ†è‡ªèº«ã‚’é™¤å¤–
            similarities[i] = -1

            # ä¸Šä½Nå€‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
            top_indices = np.argsort(similarities)[::-1][:self.max_edges_per_node]

            for j in top_indices:
                similarity = similarities[j]
                if similarity >= self.similarity_threshold:
                    node_i = self.df.iloc[i]['intent_id']
                    node_j = self.df.iloc[j]['intent_id']

                    # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ã«i < jã®æ¡ä»¶ï¼‰
                    if i < j:
                        G.add_edge(node_i, node_j, weight=float(similarity))
                        edge_count += 1

        print("âœ“ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰å®Œäº†")
        print(f"  - ãƒãƒ¼ãƒ‰æ•°: {G.number_of_nodes()}")
        print(f"  - ã‚¨ãƒƒã‚¸æ•°: {G.number_of_edges()}")
        print(f"  - å¹³å‡æ¬¡æ•°: {2 * G.number_of_edges() / G.number_of_nodes():.2f}")

        return G

    def create_interactive_html(self, G: nx.Graph, output_path: Path):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªHTMLãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç”Ÿæˆ"""
        print("ğŸ“Š ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–HTMLç”Ÿæˆä¸­...")

        # Pyvisãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ
        net = Network(
            height="900px",
            width="100%",
            bgcolor="#ffffff",
            font_color="#333333",
            notebook=False,
            directed=False
        )

        # ç‰©ç†æ¼”ç®—ã®è¨­å®š
        net.barnes_hut(
            gravity=-10000,
            central_gravity=0.3,
            spring_length=200,
            spring_strength=0.001,
            damping=0.09
        )

        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¥ã®è‰²è¨­å®š
        status_colors = {
            'idea': '#FFE082',      # é»„è‰²
            'todo': '#81C784',      # ç·‘
            'doing': '#64B5F6',     # é’
            'done': '#90CAF9',      # æ°´è‰²
            'blocked': '#E57373',   # èµ¤
            'unknown': '#BDBDBD'    # ã‚°ãƒ¬ãƒ¼
        }

        # ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
        for node_id, node_data in G.nodes(data=True):
            status = node_data['status']
            color = status_colors.get(status, '#BDBDBD')

            # ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ç”¨ã®HTMLã‚’ä½œæˆ
            intent_text = node_data['intent']
            if intent_text and len(intent_text) > 200:
                intent_text = intent_text[:200] + '...'

            facts_text = node_data['objective_facts'] or ''
            if facts_text and len(facts_text) > 200:
                facts_text = facts_text[:200] + '...'

            title = f"""
            <div style="max-width: 400px;">
                <strong>{node_id}</strong><br>
                <strong>ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:</strong> {status}<br>
                <strong>ãƒ‘ã‚¹:</strong> {node_data['full_path']}<br>
                <strong>æ™‚åˆ»:</strong> {node_data['start_time']}<br>
                <strong>å…ƒã‚¯ãƒ©ã‚¹ã‚¿:</strong> {node_data['original_cluster']}<br><br>
                <strong>æ„å›³:</strong><br>{intent_text}<br><br>
                <strong>äº‹å®Ÿ:</strong><br>{facts_text}
            </div>
            """

            # ãƒ©ãƒ™ãƒ«ã¯intent_idã®ã¿
            label = node_id

            net.add_node(
                node_id,
                label=label,
                title=title,
                color=color,
                size=20
            )

        # ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ 
        for edge in G.edges(data=True):
            source, target, data = edge
            weight = data['weight']

            # ã‚¨ãƒƒã‚¸ã®å¤ªã•ã‚’é¡ä¼¼åº¦ã«å¿œã˜ã¦èª¿æ•´
            edge_width = 1 + (weight - self.similarity_threshold) * 10

            net.add_edge(
                source,
                target,
                value=edge_width,
                title=f"é¡ä¼¼åº¦: {weight:.3f}"
            )

        # HTMLã‚’ç”Ÿæˆ
        net.save_graph(str(output_path))
        print(f"âœ“ HTMLãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {output_path}")

    def save_network_stats(self, G: nx.Graph):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆã‚’ä¿å­˜"""
        stats = {
            'n_nodes': G.number_of_nodes(),
            'n_edges': G.number_of_edges(),
            'avg_degree': 2 * G.number_of_edges() / G.number_of_nodes() if G.number_of_nodes() > 0 else 0,
            'density': nx.density(G),
            'n_connected_components': nx.number_connected_components(G),
            'config': {
                'similarity_threshold': self.similarity_threshold,
                'max_edges_per_node': self.max_edges_per_node,
                'model_name': self.model_name
            }
        }

        # æ¬¡æ•°åˆ†å¸ƒ
        degrees = [d for n, d in G.degree()]
        stats['degree_distribution'] = {
            'mean': float(np.mean(degrees)),
            'median': float(np.median(degrees)),
            'min': int(np.min(degrees)),
            'max': int(np.max(degrees))
        }

        # é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚º
        components = list(nx.connected_components(G))
        component_sizes = [len(c) for c in components]
        stats['component_sizes'] = sorted(component_sizes, reverse=True)[:10]  # ä¸Šä½10å€‹

        stats_path = OUTPUT_DIR / "network_stats.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ çµ±è¨ˆæƒ…å ±ã‚’ä¿å­˜: {stats_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse

    parser = argparse.ArgumentParser(description='ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰')

    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    parser.add_argument('--input-dir', type=str,
                       default='output/intent_extraction/processed',
                       help='ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆæŠ½å‡ºçµæœã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®š
    parser.add_argument('--similarity-threshold', type=float, default=0.7,
                       help='ã‚¨ãƒƒã‚¸ã‚’ä½œæˆã™ã‚‹æœ€å°é¡ä¼¼åº¦ (default: 0.7)')
    parser.add_argument('--max-edges-per-node', type=int, default=5,
                       help='å„ãƒãƒ¼ãƒ‰ã‹ã‚‰ä¼¸ã³ã‚‹æœ€å¤§ã‚¨ãƒƒã‚¸æ•° (default: 5)')

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    parser.add_argument('--model', type=str,
                       default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
                       help='åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å')

    args = parser.parse_args()

    print("=" * 60)
    print("ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰")
    print("=" * 60)
    print("\nè¨­å®š:")
    print(f"  å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {args.input_dir}")
    print(f"  é¡ä¼¼åº¦é–¾å€¤: {args.similarity_threshold}")
    print(f"  æœ€å¤§ã‚¨ãƒƒã‚¸æ•°/ãƒãƒ¼ãƒ‰: {args.max_edges_per_node}")
    print(f"  ãƒ¢ãƒ‡ãƒ«: {args.model}")
    print()

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
    builder = IntentNetworkBuilder(
        input_dir=Path(args.input_dir),
        model_name=args.model,
        similarity_threshold=args.similarity_threshold,
        max_edges_per_node=args.max_edges_per_node
    )

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
    G = builder.build_network()

    # çµ±è¨ˆä¿å­˜
    builder.save_network_stats(G)

    # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–HTMLç”Ÿæˆ
    html_path = OUTPUT_DIR / "network.html"
    builder.create_interactive_html(G, html_path)

    print("\nâœ… å®Œäº†ï¼")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
    print(f"ğŸ“„ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯HTML: {html_path}")


if __name__ == "__main__":
    main()
