#!/usr/bin/env python3
"""
ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ„å›³åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ - ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

messages_with_hierarchy.csv ã‹ã‚‰ ultra_intent_goal_network.json ã¾ã§ã®
å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
  python main.py run_all --csv_path=data/messages.csv
  python main.py run_all_with_rag --csv_path=data/messages.csv
  python main.py clustering --csv_path=data/messages.csv
  python main.py intent_extraction --gemini --aggregate --aggregate_all
  python main.py goal_network
  python main.py rag_build
  python main.py rag_query --query="ã“ã“1é€±é–“ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦ä½•ã‚’ã‚„ã£ã¦ã„ãŸã‹"
  python main.py rag_query_debug --topic="é–‹ç™ºãƒ„ãƒ¼ãƒ«" --status="doing,done"
"""

import sys
from pathlib import Path
from typing import TypedDict, Unpack

import fire  # type: ignore[import-untyped]

# lib/pipelines ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ã«ã™ã‚‹
sys.path.insert(0, str(Path(__file__).parent))

from lib.config import config
from lib.pipelines.goal_network_builder import build_ultra_goal_network
from lib.pipelines.intent_extraction import run_intent_extraction_pipeline
from lib.pipelines.message_clustering import ClusteringConfig, run_clustering_pipeline


class ClusteringKwargs(TypedDict, total=False):
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°"""

    embedding_weight: float
    time_weight: float
    hierarchy_weight: float
    time_bandwidth_hours: float
    method: str
    min_cluster_size: int
    min_samples: int
    n_clusters: int | None
    linkage: str
    size_min: int
    size_max: int
    n_init: int
    max_iter: int


class Pipeline:
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ„å›³åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def rag_build(
        self,
        output: str | None = None,
        chroma_db: str | None = None,
        build_chroma: bool = True,
    ):
        """
        RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰

        Args:
            output: çµ±åˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡ºåŠ›å…ˆï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            chroma_db: Chroma DBãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            build_chroma: Chromaã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ã™ã‚‹ã‹
        """
        from lib.pipelines.rag_index_builder import build_rag_index

        build_rag_index(
            output_path=output or config.rag_unified_intents_path,
            chroma_db_path=chroma_db or config.rag_chroma_db_path,
            build_chroma=build_chroma,
        )

    def rag_query(
        self,
        query: str,
        answer_with_llm: bool = True,
        save_output: bool = False,
    ):
        """
        RAGæ¤œç´¢ï¼ˆè‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªï¼‰

        Args:
            query: è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªï¼ˆä¾‹: ã€Œã“ã“1é€±é–“ã€é–‹ç™ºãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦ä½•ã‚’ã‚„ã£ã¦ã„ãŸã‹ã€ï¼‰
            answer_with_llm: LLMã§æœ€çµ‚å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã‹
            save_output: æ¤œç´¢çµæœã‚’ä¿å­˜ã™ã‚‹ã‹
        """
        from lib.pipelines.rag_query_executor import execute_rag_query

        execute_rag_query(
            query=query,
            answer_with_llm=answer_with_llm,
            save_output=save_output,
        )

    def rag_query_debug(
        self,
        topic: str | None = None,
        start_date: str | None = None,
        end_date: str | None = None,
        status: str = "todo,idea",
        top_k: int | None = None,
        subgraph_strategy: str | None = None,
        **kwargs: bool,
    ):
        """
        RAGæ¤œç´¢ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç›´æ¥æŒ‡å®šï¼‰

        Args:
            topic: ãƒˆãƒ”ãƒƒã‚¯ï¼ˆsemantic searchï¼‰
            start_date: é–‹å§‹æ—¥ï¼ˆYYYY-MM-DDï¼‰
            end_date: çµ‚äº†æ—¥ï¼ˆYYYY-MM-DDï¼‰
            status: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ä¾‹: "todo,idea"ï¼‰
            top_k: å–å¾—ä»¶æ•°ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            subgraph_strategy: ã‚°ãƒ©ãƒ•æŠ½å‡ºæˆ¦ç•¥ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            **kwargs: answer_with_llm, save_output ãªã©
        """
        from lib.pipelines.rag_query_executor import execute_rag_query_debug
        from lib.rag_models import QueryDebugParams

        params = QueryDebugParams(
            topic=topic,
            start_date=start_date,
            end_date=end_date,
            status=status,
            top_k=top_k or config.rag_top_k,
            subgraph_strategy=subgraph_strategy or config.rag_subgraph_strategy,
            answer_with_llm=kwargs.get("answer_with_llm", False),
            save_output=kwargs.get("save_output", False),
        )
        execute_rag_query_debug(params)

    def clustering(
        self,
        csv_path: str | None = None,
        **kwargs: Unpack[ClusteringKwargs],
    ):
        """
        ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°

        Args:
            csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            **kwargs: ClusteringConfigã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                embedding_weight: åŸ‹ã‚è¾¼ã¿é‡ã¿ (default: config.yaml or 0.7)
                time_weight: æ™‚é–“é‡ã¿ (default: config.yaml or 0.15)
                hierarchy_weight: éšå±¤é‡ã¿ (default: config.yaml or 0.15)
                time_bandwidth_hours: æ™‚é–“ã‚«ãƒ¼ãƒãƒ«å¸¯åŸŸå¹… (default: config.yaml or 168.0)
                method: ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³• (default: config.yaml or "kmeans_constrained")
                size_min: æœ€å°ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (default: config.yaml or 10)
                size_max: æœ€å¤§ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚º (default: config.yaml or 50)
        """
        clustering_config = ClusteringConfig(
            csv_path=csv_path or config.csv_path, **kwargs
        )
        run_clustering_pipeline(clustering_config)

    def intent_extraction(
        self,
        gemini: bool = False,
        cluster: int | None = None,
        save_raw: bool = False,
        aggregate: bool = False,
        aggregate_all: bool = False,
        max_workers: int | None = None,
    ):
        """
        ã‚¹ãƒ†ãƒƒãƒ—2: æ„å›³æŠ½å‡ºã¨éšå±¤åŒ–

        Args:
            gemini: Gemini APIã§æ„å›³æŠ½å‡ºã‚’å®Ÿè¡Œ
            cluster: ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã‚¿IDã®ã¿å‡¦ç†
            save_raw: ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
            aggregate: ä¸Šä½æ„å›³ã‚’ç”Ÿæˆ
            aggregate_all: æœ€ä¸Šä½æ„å›³ã‚’ç”Ÿæˆ
            max_workers: ä¸¦åˆ—å®Ÿè¡Œã®æœ€å¤§ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        """
        run_intent_extraction_pipeline(
            gemini=gemini,
            cluster=cluster,
            save_raw=save_raw,
            aggregate=aggregate,
            aggregate_all=aggregate_all,
            max_workers=max_workers or config.intent_extraction_max_workers,
        )

    def goal_network(
        self,
        input_path: str | None = None,
        ultra_id: int | None = None,
        save_prompts: bool = False,
    ):
        """
        ã‚¹ãƒ†ãƒƒãƒ—3: ã‚´ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰

        Args:
            input_path: ultra_intents_enriched.jsonã®ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            ultra_id: å‡¦ç†å¯¾è±¡ã®Ultra Intent ID
            save_prompts: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
        """
        build_ultra_goal_network(
            input_path=input_path or config.goal_network_input_path,
            ultra_id=ultra_id,
            save_prompts=save_prompts,
        )

    def run_all(
        self,
        csv_path: str | None = None,
        save_prompts: bool = False,
    ):
        """
        å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ: clustering â†’ intent_extraction â†’ goal_network

        Args:
            csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            save_prompts: ã‚´ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
        """
        input_csv = csv_path or config.csv_path
        print("=" * 60)
        print("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ„å›³åˆ†æãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³")
        print("=" * 60)
        print(f"å…¥åŠ›: {input_csv}\n")

        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        print("\n" + "=" * 60)
        print("ã‚¹ãƒ†ãƒƒãƒ— 1/3: ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
        print("=" * 60)
        self.clustering(csv_path=input_csv)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        cluster_output = Path("output/message_clustering/clustered_messages.csv")
        if not cluster_output.exists():
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {cluster_output} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        print(f"\nâœ“ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ: {cluster_output}")

        # ã‚¹ãƒ†ãƒƒãƒ—2: æ„å›³æŠ½å‡ºã¨éšå±¤åŒ–
        print("\n" + "=" * 60)
        print("ã‚¹ãƒ†ãƒƒãƒ— 2/3: æ„å›³æŠ½å‡ºã¨éšå±¤åŒ–")
        print("=" * 60)
        self.intent_extraction(
            gemini=True,
            aggregate=True,
            aggregate_all=True,
        )

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        ultra_intents_output = Path(
            "output/intent_extraction/cross_cluster/ultra_intents_enriched.json"
        )
        if not ultra_intents_output.exists():
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {ultra_intents_output} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        print(f"\nâœ“ ã‚¨ãƒ³ãƒªãƒƒãƒæ¸ˆã¿æœ€ä¸Šä½æ„å›³: {ultra_intents_output}")

        # ã‚¹ãƒ†ãƒƒãƒ—3: ã‚´ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰
        print("\n" + "=" * 60)
        print("ã‚¹ãƒ†ãƒƒãƒ— 3/3: ã‚´ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹ç¯‰")
        print("=" * 60)
        self.goal_network(save_prompts=save_prompts)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        goal_network_output = Path("output/goal_network/ultra_intent_goal_network.json")
        if not goal_network_output.exists():
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {goal_network_output} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "=" * 60)
        print("âœ… å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†ï¼")
        print("=" * 60)
        print("\nğŸ“ ä¸»è¦ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print("  1. output/message_clustering/clustered_messages.csv")
        print("  2. output/message_clustering/clustering_report.html")
        print("  3. output/intent_extraction/cross_cluster/ultra_intents_enriched.json")
        print("  4. output/goal_network/ultra_intent_goal_network.json")

        if save_prompts:
            print("  5. output/goal_network/ultra_prompts_responses/")

    def run_all_with_rag(
        self,
        csv_path: str | None = None,
        save_prompts: bool = False,
    ):
        """
        å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        clustering â†’ intent_extraction â†’ goal_network â†’ rag_build

        Args:
            csv_path: å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
            save_prompts: ã‚´ãƒ¼ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
        """
        # åŸºæœ¬ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        self.run_all(csv_path=csv_path or config.csv_path, save_prompts=save_prompts)

        # ã‚¹ãƒ†ãƒƒãƒ—4: RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰
        print("\n" + "=" * 60)
        print("ã‚¹ãƒ†ãƒƒãƒ— 4/4: RAGã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰")
        print("=" * 60)
        self.rag_build()

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        unified_intents_output = Path("output/rag_index/unified_intents.jsonl")
        chroma_db_output = Path("output/rag_index/chroma_db")
        if not unified_intents_output.exists():
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {unified_intents_output} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)
        if not chroma_db_output.exists():
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {chroma_db_output} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            sys.exit(1)

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "=" * 60)
        print("âœ… å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ + RAGæ§‹ç¯‰å®Œäº†ï¼")
        print("=" * 60)
        print("\nğŸ“ ä¸»è¦ãªå‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
        print("  1. output/message_clustering/clustered_messages.csv")
        print("  2. output/message_clustering/clustering_report.html")
        print("  3. output/intent_extraction/cross_cluster/ultra_intents_enriched.json")
        print("  4. output/goal_network/ultra_intent_goal_network.json")
        print("  5. output/rag_index/unified_intents.jsonl")
        print("  6. output/rag_index/chroma_db/")

        if save_prompts:
            print("  7. output/goal_network/ultra_prompts_responses/")

        print("\nğŸ’¡ RAGæ¤œç´¢ã‚’è©¦ã™ã«ã¯:")
        print('  make rag-query QUERY="ã“ã“1é€±é–“ã€ä½•ã‚’ã‚„ã£ã¦ã„ãŸã‹"')


if __name__ == "__main__":
    fire.Fire(Pipeline)
